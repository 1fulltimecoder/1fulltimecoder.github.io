<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Operating System Notes For Placement | Samir Paul</title>
<meta name=keywords content="Operating System Notes For Placement,Coding blog,Computer Science"><meta name=description content="Operating System Notes For Tech Placements"><meta name=author content="Samir Paul"><link rel=canonical href=https://samirpaulb.github.io/posts/operating-system-notes-for-placement/><meta name=google-site-verification content="vJAOBxbJTCK2vXG-hLFeGsoC9hXgFlCpuJJ8AcJLROQ"><meta name=yandex-verification content="fe6a06c57be84984"><meta name=msvalidate.01 content="1A92FC2EC113F8616A21D76DA684A133"><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://samirpaulb.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://samirpaulb.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://samirpaulb.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://samirpaulb.github.io/apple-touch-icon.png><link rel=mask-icon href=https://samirpaulb.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=manifest href=/manifest.json><link rel=sitemap type=application/xml title=Sitemap href=https://samirpaulb.github.io/sitemap.xml><link rel=alternate type=application/rss+xml title=RSS href=https://samirpaulb.github.io/index.xml><meta content="@SamirPaulb" name=twitter:site><meta content="@SamirPaulb" name=twitter:creator><meta content="24bac6e1fbf1750de40d59bb788d9dd9" name=p:domain_verify><meta content="6800281970014175" property="fb:app_id"><meta content="3pkgruuk3kzlsn3jdfehgbd4sem1qb" name=facebook-domain-verification><meta content="n93bHAYCJyRzj_9ccNNLKYUj03U0eWuhdV5Gb-bv2_g" name=google-site-verification><meta name=google-site-verification content="uziThFIJ1huzKLCKv-DChPbWZTRRFqmmdA6pcA-dqzs"><meta content="2xno70lnqo1ajcykeat10qud6lat0xlkc2bskxz0k9ma74g0bn-kprra5ev6bwui2s6-2394l0ryopjet7yt3hs8tokilug2cfhocw3r0nlj2t1xx690tgu82t59wtwi" name=norton-safeweb-site-verification><meta content="NHI3em00K1U3WmRGTTRHeWVGNUdNZz090" name=dmca-site-verification><link href=//fonts.googleapis.com rel='preconnect dns-prefetch'><link href=//storage.googleapis.com rel='preconnect dns-prefetch'><link href=//use.fontawesome.com rel='preconnect dns-prefetch'><link href=//ajax.googleapis.com rel='preconnect dns-prefetch'><link href=//ajax.microsoft.com rel='preconnect dns-prefetch'><link href=//github.com rel='preconnect dns-prefetch'><link href=//cdnjs.cloudflare.com rel='preconnect dns-prefetch'><link href=//www.google-analytics.com rel='preconnect dns-prefetch'><link href=//pagead2.googlesyndication.com rel='preconnect dns-prefetch'><link href=//googleads.g.doubleclick.net rel='preconnect dns-prefetch'><link href=//www.gstatic.com rel='preconnect dns-prefetch'><link href=//www.googletagmanager.com rel='preconnect dns-prefetch'><link href=//www.googletagservices.com rel='preconnect dns-prefetch'><link href=//static.xx.fbcdn.net rel='preconnect dns-prefetch'><link href=//tpc.googlesyndication.com rel='preconnect dns-prefetch'><link href=//apis.google.com rel='preconnect dns-prefetch'><link href=//www.w3.org rel='preconnect dns-prefetch'><link href=//www.facebook.com rel='preconnect dns-prefetch'><link href=//connect.facebook.net rel='preconnect dns-prefetch'><link href=//disqus.com rel='preconnect dns-prefetch'><link href=//samirpaul.disqus.com rel='preconnect dns-prefetch'><link href=//www.youtube.com rel='preconnect dns-prefetch'><link href=//img.youtube.com rel='preconnect dns-prefetch'><link href=//www.pinterest.com rel='preconnect dns-prefetch'><link href=//www.linkedin.com rel='preconnect dns-prefetch'><link href=//player.vimeo.com rel='preconnect dns-prefetch'><link href=//amazonaws.com rel='preconnect dns-prefetch'><link href=//s3.amazonaws.com rel='preconnect dns-prefetch'><link href=//s3.buysellads.com rel='preconnect dns-prefetch'><link href=//stats.buysellads.com rel='preconnect dns-prefetch'><link href=//scdn.netlify.app rel='preconnect dns-prefetch'><link href=//spcdn.pages.dev rel='preconnect dns-prefetch'><link href=//scdn.web.app rel='preconnect dns-prefetch'><link href=//user-images.githubusercontent.com rel='preconnect dns-prefetch'><link href=//raw.githubusercontent.com rel='preconnect dns-prefetch'><link href=//cdn.jsdelivr.net rel='preconnect dns-prefetch'><link href=//res.cloudinary.com rel='preconnect dns-prefetch'><link href=//cloudinary.com rel='preconnect dns-prefetch'><link href=//imgur.com rel='preconnect dns-prefetch'><link href=//i.imgur.com rel='preconnect dns-prefetch'><link href=//firebaseio.com rel='preconnect dns-prefetch'><link href=//translate.googleapis.com rel='preconnect dns-prefetch'><link href=//google.com rel='preconnect dns-prefetch'><link href=//analytics.google.com rel='preconnect dns-prefetch'><link href=//cse.google.com rel='preconnect dns-prefetch'><script async src="https://www.googletagmanager.com/gtag/js?id=G-CP4QE6ZEV0"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-CP4QE6ZEV0",{anonymize_ip:!1})}</script><meta property="og:title" content="Operating System Notes For Placement"><meta property="og:description" content="Operating System Notes For Tech Placements"><meta property="og:type" content="article"><meta property="og:url" content="https://samirpaulb.github.io/posts/operating-system-notes-for-placement/"><meta property="og:image" content="https://res.cloudinary.com/samirpaul/image/upload/w_1100,c_fit,co_rgb:FFFFFF,l_text:Arial_75_bold:Operating System Notes For Placement/og-image.webp"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-06-20T00:00:00+00:00"><meta property="article:modified_time" content="2023-06-20T00:00:00+00:00"><meta property="og:see_also" content="https://samirpaulb.github.io/posts/data-structures-and-algorithms-for-coding-interview/"><meta property="og:see_also" content="https://samirpaulb.github.io/posts/some-of-my-online-courses-certificates/"><meta property="og:see_also" content="https://samirpaulb.github.io/posts/curated-list-of-project-based-tutorials/"><meta property="og:see_also" content="https://samirpaulb.github.io/posts/binary-search-template/"><meta property="og:see_also" content="https://samirpaulb.github.io/posts/complete-computer-science-study-plan-to-become-a-software-engineer/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://res.cloudinary.com/samirpaul/image/upload/w_1100,c_fit,co_rgb:FFFFFF,l_text:Arial_75_bold:Operating System Notes For Placement/og-image.webp"><meta name=twitter:title content="Operating System Notes For Placement"><meta name=twitter:description content="Operating System Notes For Tech Placements"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog Posts","item":"https://samirpaulb.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Operating System Notes For Placement","item":"https://samirpaulb.github.io/posts/operating-system-notes-for-placement/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Operating System Notes For Placement","name":"Operating System Notes For Placement","description":"Operating System Notes For Tech Placements","keywords":["Operating System Notes For Placement","Coding blog","Computer Science"],"articleBody":"Operating Systems Overview Download PDF Notes➥ Operating Systems :\nDirect operational resources [CPU, memory, devices] Enforces working policies [Resource usage, access] Mitigates difficulty of complex tasks [abstract hardware details (using system calls)] What is an Operating System? Intermediate between Hardware and Software applications Hides hardware complexity (Read/write file storage, send/receive socket network) Handles resource management (CPU scheduling, Memory management) Provide isolation and protection (allocate different parts of memory to different applications so that applications don’t overwrite other memory locations) Operating System definition: An Operating System is a layer of systems software that:\ndirectly has privileged access to the underlying hardware; hides the hardware complexity; manages hardware on behalf of one or more application according to some predifined policies. In addition, it ensures that applications are isolated and protected from one another. Operating System examples: Desktop Embedded devices Microsoft Windows Android OS MAC OS X (BSD) iOS LINUX Symbian … … OS Elements Abstractions (corresponds to applications that OS executes) process, thread, file, socket, memory page Mechanisms (on top of Abstractions) create, schedule, open, write, allocate Policies (how mechanisms are used to manage underlying hardware) Least Recently Used (LRU) , Earliest Deadline First (EDF), etc. Example : Memory Management:\nAbstractions: Memory page Mechanisms: Allocate, map to a process Policies: LRU OS Design Principles Seperation of mechanism and policy implement flexible mechanisms to support many policies e.g. LRU, LFU, random Optimize for common case Where will the OS be used? What will the user want to execute on that machine? What are the workload requirements? User/ Kernel Protection Boundary user-level =\u003e applications [underprivileged mode] kernel-level =\u003e OS Kernel [privileged access, hardware access] User-Kernel switch is supported by hardware. using trap instructions system calls like: open (file) send (socket) malloc (memory) signals System call Flowcart To make a system call, an application must: write arguments save relevant data ast well defined location make system calls using system call number In synchronous mode : wait until system call completes. Basic OS services process management file management device management memory management storage management security Linux System Calls Task Commands Process Control fork (); exit(); wait(); File Manipulation open(); read(); write(); Device Manipulation ioctl(); read(); write(); Information Maintenance getpid(); alarm(); sleep(); Communication pipe(); shmget(); mmap(); Protection chmod(); umask(); chown(); Linux Architecture Process and Process Management Process: Instance of an executing program.\nState of execution program counter, stack pointer Parts and temporary holding area data, register state, occupies state in memory May require special hardware I/O devices Process is a state of a program when executing and loaded in memory (active state) as opposed to application (static state).\nWhat does a process look like? Type of state Text and Data static state when process loads first Heap dynamically created during execution Stack grows and shrinks LIFO queue (used to store task checkpoints to resume the original process after switching from another.) How does the OS know what a process is doing? Using:\nProgram counter CPU registers Stack pointer Process Control Block (PCB) PCB created when process is created Certain fields are updated when process state change e.g. memory mapping or other fields that change very frequently e.g. Program Counter How is PCB used ? Context Switch Mechanism used to switch from the context of one process to another in the CPU. They are expensive! direct costs: no of cycles for load and store instructions. indirect costs: COLD cache (read more here) Therefore limit frequency how context switching is done. When a cache is HOT, most process data is in the cache so the process performance will be at its best.\nSometimes there are situations where we have to Context Switch (higher priority process, timesharing, etc.)\nProcess Lifecycle CPU is able to execute a process when the process is in Running or Ready state.\nProcess Creation Mechanisms: fork :\ncopies the parent PCB into new child PCB child contains execution at instruction after fork exec :\nreplace child image load new program and start from first instruction What is the role of CPU scheduler? CPU scheduler determines which one of the currently ready processes will be dispatched to the CPU to start running, and how long it should run for.\nOS must :\npreempt =\u003e interrupt and save current context schedule =\u003e run scheduler to choose next process dispatch =\u003e dispatch process 2 switch into its context Scheduling design decisions What are the appropriate timeslice values? Metrics to choose next process to run? I/O A process can make way in the ready queue in a number of ways.\nCan process interact? Inter Process communication: IPC mechanisms:\ntransfer data/info between address space maintain protection and isolation provide flexibility and performance Two types of IPC models:\n1. Message Passing IPC OS provides communication channel line shared buffer Processes can write(send), read(receive) msg to/from channel Advantages: OS manages the channel\nDisadvantages: Overheads\n2. Shared Memory IPC OS establishes a shared channel and maps it into each processes’ address space Processes directly write(send), read(receive) msg to/from this memory Advantages: OS is out of the way after establishing the shared channel\nDisadvantages: Re-implementing a lot of code that could have been done by the OS\nOverall, shared memory based communication is better if mapping memory between two processes is ammortized over a large number of messages.\nThreads and Concurrency Thread:\nis an active entity executing unit of a process works simultaneously with others many threads execute together requires coordination sharing of I/O devices, CPUs, memory Process vs Thread Why are threads useful? Parallelization =\u003e Speedup Specialization =\u003e Hot cache Efficiency =\u003e lower memory requirement \u0026 cheaper IPC Time for context switch in threads is less, since memory is shared, hence mapping is not required between virtual and physical memory. Therefore multithreading can be used to hide latency. Benefits to both applicatioons and OS code Multithreaded OS kernel threads working on behalf of applications OS level services like daemons and drivers What do we need to support threads? Threads data structure Identify threads, keep track of resource usage.. Mechanisms to create and manage threads Mechanisms to safely coordinate among threads running concurrently in the same address space Concurrency control and Coordination Mutual exclusion Exclusive access to only one thread at a time mutex Waiting on other threads Specific condition before proceeding condition variable Waking up other threads from wait state Threads and Threads creation Thread data structure:\nThread type, Thread ID, PC, SP, registers, stack, attributes. Fork(proc, args)\ncreate a thread not UNIX fork 1 t1 = fork(proc, args) Join(thread) terminate a thread 1 child_result = join(t1) Example: 1 2 3 4 5 Thread t1; Shared_List list; t1 = fork(safe_insert, 4); safe_insert(6); join(t1); //Optional The list can be accessed by reading shared variable.\nMutual Exclusion Mutex data structure: locked?, owner, blocked_threads 1 2 3 4 5 lock(mutex){ //Critical Section //Only one thread can access at a time } unlock(mutex) Producer Consumer problem What if the processing you wish to perform with mutual exclusion needs to occur under certai conditions?\nFor e.g. The producer appends items to a list until the list is full, and the consumer has to print out all the items of the list once the list if full and then empty the list. Thus we have to execute the Consumer thread only under a certain condition (here- when the list becomes empty, print items).\nSolution: Use Condition Variables\nWait(mutex, condition)\nmutex is automatically released and reaquired on wait The consumer applies Wait until the list is full Signal(condition)\nNotify only one thread waiting on condition The Producer applies Signal to the Consumer thread when the list is full Broadcast(condition)\nNotify all waiting threads Readers / Writer problem 0 or more readers can access a resource 0 or 1 writer can write the resource concurrently at the same time One solution:\nlock on resource good for writer too restrictive for readers Better solution:\n1 2 3 4 5 6 if ((read_count == 0) \u0026 (read_count == 0)) R okay, W okay if (read_count \u003e 0) R okay if (read_count == 1) R not-okay, W not-okay State of shared resource:\nfree : resource_counter = 0 reading : resource_counter \u003e 0 writing : resource_counter = -1 Thus essentially we can apply mutex on the new proxy ‘resource_counter’ variable that represents the state of the shared resource.\nAvoiding common mistakes keep track of mutex/lock variable used with a resource e.g. mutex_type m1; // mutex for file1 check that you are always and correctly using lock and unlock - Compilers can be used as they generate errors/warnings to correct this type of mistake Use a single mutex to access a single resource check that you are signalling correct condition check that you are not using signal when broadcast is needed signal : only 1 thread is will proceed, remaining threads will wait check thread execution order to be controlled by signals to condition variables Spurious(Unnecessary) Wake ups When we wake up threads knowing they may not be able to proceed.\nDeadlocks Two or more competing threads are said to be in a deadlock if they are waiting on each other to complete, but none of them ever do.\nHere T1 and T2 are in deadlock.\nHow to avoid this? Unlock T1 before locking T2 Fine-grained locking but T1 nad T2 may both be required Use one mega lock, get all locks upfront, then release at end For some applications this may be ok. But generally its too restrictive and limits parallelism Maintain lock order first m_T1 then m_T2 this will prevent cycles in wait graph A cycle in wait graph is necessary and sufficient for deadlock to occur.\n(thread-waiting-on-resource —edge—\u003e thread-owning-resource)\nDeadlock prevention =\u003e Expensive\nPre-check for cycles and then delay process or change code\nDeadlock Detection and Recovery =\u003e Rollback\nKernel vs User level Threads Three types of models:\n1. One to One model: Advantages:\nOS sees threads Synchronization Blocking Disadvantages:\nMust go to OS for all operations OS may have limits on policies, threads Portability 2. Many to One model: Advantages:\nTotally Portable Doesn’t depend on OS limits and policies Disadvantages:\nOS may block entire process if one user-level thread blocks on I/O 3. Many to Many model: Advantages:\nBest of both worlds Can have bound or unbound threads Disadvantages:\nRequires coordination between user and kernel level thread managers Multithreading patterns 1. Boss-Workers pattern\nBoss- assigns work Workers- perform entire task Throughput of system is limited by boss thread. Hence boss thread must be kept efficient.\nThroughput = 1/boss-time-orders\nBoss assigns works by:\nDirectly signalling specific works + workers don’t need to sync - boss must keep track of everyone Placing work in queue + boss doesn’t neeed to know details about workers - queue synchronization How many workers?\non demand pool of workers static vs dynamic (i.e dynamically increasing size according to work) Advantages:\nSimplicity Disadvantages:\nThread pool management Locality 1B. Boss-Workers pattern variant\nHere workers are specialized for certain tasks opposite to the previous equally created workers Advantages:\nBetter locality Quality of Service management Disadvantages:\nLoad balancing 2. Pipeline pattern\nThreads assigned one subtask in the system Entire task = Pipeline of threads Multiple tasks concurrently run in the system, in different pipeline stages Throughput depends on weakest link Shared buffer based communication between stages 3. Layered pattern\nLayers of threads are assigned group of related subtasks End to end task must pass up and down through all layers Advantages:\nSpecialization Less fine-grained than pipeline Disadvantages:\nNot suitable for all applications Synchronization Example: Q) For 6 step toy order application we have 2 solutions:\nBoss-workers solution Pipeline solution Both have 6 threads. In the boss-workers solution, a worker produces a toy order in 120 ms. In the pipeline solution, each of 6 stages take 20 ms.\nHow long will it take for these solutions to complete 10 toy orders and 11 toy orders?\nA) 6 threads means for Boss-workers, 1 thread is for boss, 5 for workers. In pipeline 6 threads are equally used.\nFor 10 toy orders:\n1 2 Boss-workers(10) = 120 + 120 = 240 ms Pipeline(10) = 120 + (9*20) = 300 ms Here Boss-workers is better than Pipeline.\nFor 11 toy orders:\n1 2 Boss-workers(11) = 120 + 120 + 120 = 360 ms Pipeline(11) = 120 + (10*20) = 320 ms Here Pipeline is better than Boss-workers.\nThis proves that choosing a better pattern depends on the number of threads and the work required to be done.\nPThreads PThreads == POSIX Threads\nPOSIX = Portable OS interface\nCompiling PThreads #include in main file Compile source with -lpthread or -pthread 1 2 gcc -o main main.c -lpthread gcc -o main main.c -pthread Check return values of common examples PThread mutexes to solve mutual exclusion problems among concurrent threads Safety tips Shared data should always be accessed through single mutex Mutex scope must be visible to all Globally order locks for all threads, lock mutexes in order Always unlock a mutex (correctly) Thread Design Considerations Kernel vs User Level Threads Thread related data structures Hard vs Light Process states PCB is divided into multiple data structures classified as follows:\nLight Process states Signal mask System call args Heavy Process states virtual address mapping Rationale for Multiple Data Structures: Single PCB Multiple DS Large continuos DS Smaller DS Private for each entity Easier to share Saved and restored on each context switch Save and Restore only what needs to change on context switch Update for any changes User lever library need to only update portion of the state Thus the following disadvantages for single PCB become advantages for Multiple DS : Scalability Overheads Performance Flexibility Comparison of Interrupts and Signals Handled in specific ways - interrupt and signal handlers Can be ignored interrupt and signal mask Expected or unexpected appear synchronously or asynchronously Difference: Interrupts Signals Events generated externally by components other than CPU (I/O devices, timers, other CPUs) Events triggered by CPU and software running on it Determined based on physical platform Determined based on OS Appear asynchronously Appear synchronously or asynchronously Similarities: Have a unique ID depending on h/w or OS Can be masked and disabled/suspended via corresponding mask per-CPU interrupt mask, preprocess signal mask if enabled, trigger corresponding to handler interrupt handler set for entire system by OS signal handler set on per process basis by process An interrupt is like a snowstorm alarm\nA signal is like a low battery warning\nInterrupts Signals Handlers / Actions Default actions Terminate, ignore Terminate and core dump Stop or continue Process Installs Handler signal(), sigaction() for most signals, some cannot be “caught” Synchronous SIGSEGV (access to protected memory) SIGFPE (divided by zero) SIGKILL (kill, id) can be directed to a specific thread Asynchronous* SIGKILL (kill) SIGALARM Why disable Interrupts or Signals Here PC: First instruction in handler\nSP : thread stack\nTo prevent deadlock,\nKeep handler code simple avoid mutex - too restrictive Control interruptions by handler code Use interrupt/signal masks 0011100110.. (0: disabled, 1: enabled) 1 2 3 4 5 6 7 8 9 10 11 clear_field_in_mask(mask) lock(mutex) { #disabled =\u003e remaining pending } unlock(mutex) reset_field_in_mask(mask) #enabled =\u003e execute handler code Interrupt masks are per CPU\nif mask disables interrupt, hardware interrupt rounting mechanism will not deliver interrupt Signal are per execution context (User-level thread on top of Kernel-level thread)\nif mask disables signal, kernel sees mask and will not interrupt corresponding thread Types of Signals One-shot Signals “n signals pending == 1 signal pending” : atleast once must be explicitly re-enabled Realtime Signals “if n signals raised, then handler is called n times” Handling interrupts as threads but dynamic thread creation is expensive!\nDynamic decision if handler doesn’t lock execute on interrupted threads stack if handler can block turn into real thread Optimization pre-create and pre-initialize thread structure for interrupt routines Threads and Signal Handling Case 1 :\nUser-Level-Thread mask = 1 Kernel-Level-Thread mask = 1 Case 2 :\nUser-Level-Thread mask = 0 Kernel-Level-Thread mask = 1 another User-Level-Thread mask = 1 Case 3 :\nUser-Level-Thread mask = 0 Kernel-Level-Thread mask = 1 another User-Level-Thread mask = 1 another Kernel-Level-Thread mask = 1 Case 4 :\nUser-Level-Thread mask = 0 Kernel-Level-Thread mask = 1 all User-Level-Thread mask = 0 Optimize common case\nsignals less frequennt than signal mask updates system calls avoided cheaper to update user-level mask signal handling more expensive Multi-processing vs Multi-threading How to best provide concurrency?\nMulti-Processing (MP) Advantages\nSimple programming Disadvantages\nHigh memory usage Costs context switch costly to maintain shared state (tricky port setup) Multi-Threading (MP) Advantages\nShared address space Shared state (no sys calls to other threads) Cheap context switch Disadvantages\nComplex implementation Requires synchronization Requires underlying support for threads Event Driven model Features:\nSingle address space Single process Single thread of control Dispatcher : acts as a state machine and accepts any external events\nWhen call handler =\u003e jump to code\nThe handler:\nRuns to completion if they need to block initiate blocking operation and pass control to dispatch loop Concurrent execution in Event-driven models MP \u0026 MT : 1 request per execution context (process/thread) Event Driven : Many requests interleaved in an execution context Single thread switches among processing of different requests Process requests until wait is necessary then switch to another request Advantages\nSingle address space Single flow of control Smaller memory requirement Event Driven model requires less memory than Boss-workers/Pipeline model, where the extra memory is required for helper thread for concurrent blocking I/O not for all concurrent requests. No context switches No synchronization Disadvantages\nA blocking request/handler will block entire process Asynchronous I/O operations Asynchronous I/O operations fit well with Event-driven models\nSince asynchronous calls are not easily avalible, helpers can be used to implement the async call functionality:\ndesignated for blocking I/O operations only pipe/socket based communication with event dispatcher select()/ poll() still okay helper blocks, but main event loop (\u0026 process) will not Asymmetric Multi-Process Event Driven model (AMPED \u0026 AMTED) Advantages\nResolve portability limitations of basic event driven model Smaller footprint than regular worker thread Disadvantages\nApplicability to certain classes of applications Event routing on multi CPU systems Eg Apache Web Server\nCore : basic server skeleton Modules : per functionality Flow of Control : Similar to Event Driven model But its an combination of MP + MT, each process = boss/worker with dynamic thread pool number of processes can also be dynamically adjusted Scheduling Operating System perform scheduling in the following simple ways:\nDispatch orders immediately scheduling is simple FIFO (First-Come-First-Serve) Dispatch simple orders first maximize number of orders processed over time maximize throughput (SJF) Dispatch complex orders first maximize utilization of CPU, devices, memory CPU Scheduler Decides how and when process (and their threads) access shared CPUs Schedules tasks running at user level processes/threads as well as kernel level threads Chooses one of the ready tasks to run on CPU Runs when CPU becomes idle new task becomes ready timeslice expired timeout Context switch, enter user mode, set PC and go! \u003c= Thread is dispatched on CPU.\nWhich task should be selected? Scheduling policy/algorithm How is this done? Depends on runqueue data structure “Run-to-completion” Scheduling Initial assumptions group of tasks/jobs known execution time no preemption single CPU Metrics throughput average job completion time average job wait time CPU utilization Scheduling algorithms: 1. First Come First Serve (FCFS) Schedules tasks in order of arrival 1 runqueue = queue(FIFO) If T1, T2, T3 arrive in the given order and T1 has execution time 1s, T2 10s and T3 1s then :\nThroughput = 3/(1+10+1) = 3/12 = 0.25s Average completion time = (1 + 11 + 12)/3 = 8s Average wait time = (1+1+11)/3 = 4s Starvation NOT possible 2. Shortest Job First (SJF) Schedules tasks in order of execution time Therefore for the above example, T1(1s) \u003e T3(1s) \u003e T2(10s) Starvation possible 1 2 3 4 5 runqueue = ordered(queue) //or runqueue = tree() For SJF,\nThroughput = 3/(1+10+1) = 3/12 = 0.25s Average completion time = (1 + 2 + 12)/3 = 5s Average wait time = (0+1+2)/3 = 1s Preemptive Scheduling SJF + Preemption Starvation is possible T2 arrives first.\nPriority Scheduling Tasks have different priority levels Run highest priority task next (preemption) Starvation is possible 1 2 3 4 5 runqueue = per priority_queue() //or runqueue = tree() ordered on priority low priority task stuck in runqueue =\u003e starvation “priority aging” priority = f(actual priority, time spent in runqueue) eventually tasks will run prevents starvation 3. Round-Robin Scheduling Pick up the first task from queue (like FCFS) Task may yield to wait on I/O (unlike FCFCS) Starvation is NOT possible 4. Shortest Remaining Time First (SRTF) Chooses the process with the shortest CPU burst remaining and executes that one. If processes come in during execution that have less remaining time, the current one is preempted and the new one executed. Therefore, it can lead to starvation. Timeslicing Timeslice = max amount of uninterrupted time given to a task task may run less than timeslice has to wait on I/O sync will be placed on queue higher priority task becomes runnable using timeslice tasks are interleaved timesharing the CPU CPU bound tasks =\u003e preemption after timeslice Advantages\nShort tasks finish sooner More responsive Lengthy I/O operations initiated sooner best to keep timeslice \u003e context-switch-time Disdvantages\nOverheads How long should a timeslice be be? should balance benefits and overheads For CPU bound tasks: Hence, for CPU bound tasks, larger timeslice values are better For I/O bound tasks: Hence, for I/O bound tasks, smaller timeslice values are better Keeps CPU and I/P devices busy, I/O bound tasks run quickly, makes I/O requests responds to a user. Summary CPU bound tasks prefer longer timeslices\nlimits context switching overheads keeps CPU utilization and throughput I/O bound tasks prefer smaller timeslices\nHowever, if all the tasks in contention are I/O bound, it may not make such a difference If a portion of them are I/O smaller timeslices keeps CPU and device utilization high Provides better user-perceived performance Memory Management Operating systems:\nuses intelligently size containers memory pages of segments Not all parts are needed at once tasks operate on subset of memory Optimized for performance reduce time to access state in memory leads to better performance! Memory Management Goals Virtual vs Physical memory Allocate allocation, replacement Arbitrate address translation and validation Page-based Memory Management Allocate =\u003e pages =\u003e page frames Arbitrate =\u003e page tables Segment-based Memory Management Allocate =\u003e segments Arbitrate =\u003e segment registers Hardware Support Memory Management Unit (MMU) translate virtual to physical address reports faults (illegal access, permission, not present in memory) Registers pointers to page tables base and limit size, number of segments Cache Translation lookaside buffer Valid VA-PA translations using TLB Translation Actual PA generation done in hardware Page Tables OS creates page table per process On context switch, switch to valid page table Updates register that points to correct page table. E.g CR3 on x86 architecture Page Table Entry (PTE) Flags Present (valid/invalid) Dirty (written to) Accessed (for read or write) Protection bits =\u003e RWX Page Table Entry on x86 Flags Present Dirty Accessed R/W permission bit 0: R only, 1: R/W U/S permission bit 0: usermode, 1: superviser mode only others: caching related info (write through, caching disabled) unused: for future use Page faults Page Table Size 32 bit architecture Page Table Entry (PTE) = 4 Bytes, including PFN + flags Virtual Page Number (VPN) = 2^32/page_size Page size = 4KB (…8KB, 2MB, 4MB, 1GB) Therefore Page Table Size = (2^32 * 2^12)*4B = 4MB (per process)\nfor 64 bit architecture Page Table Entry (PTE) = 8 Bytes Page size = 4KB Page Table Size = (2^64 * 2^12)*8B = 32PB (per process!)\nprocesses don’t use entire address space even on 32 bit architecture, it will not always use all 4GB But Page Table assumes an entry per VPN regardless, of whether corresponding virtual memory is needed or not.\nHierarchical Page Tables On malloc, a new internal page table may be allocated.\nAddress split: Page Number offset P1 P2 d 12 10 10 inner table addresses =\u003e 2^10 * page_size = 2^10*2^10 = 1MB don’t need an inner table for each 1MB virtual memory gap Additional Layers\npage table directory pointer (3rd level) page table directory map (4th level) Important on 64 bit architectures larger and more sparse =\u003e larger gaps would save more internal page table components Tradeoffs of Multilevel Page Tables Advantages\nSmaller internal page tables/directories Granularity of coverage Potentially reduced page table size Disadvantages\nMore memory accesses required for translation increased translation latency Overheads of Address Translation For each memory reference :\nSingle level page table Four level page table x1 access to PTE x4 accesses to PTE x1 access to mem x1 access to mem which results in slowdown.\nPage Table Cache Translation Lookaside Buffer MMU level address translation cache On TLB miss =\u003e page table access from memory has protection/validity bits small number of cached address =\u003e high TLB hit rate temporal and spatial locality Example x86 Core i7 per core : 64-entry data TLB 128-entry instruction TLB 512-entry shared second-level TLB Inverted Page Tables Hashing Page Tables Segmentation Segmentation is the process of mapping virtual to physical memory using segments.\nSegments: arbitrary granularity (size) e.g. code, heap, data, stack.. address = segment - selector + offset Segment contiguous physical memory segment size = segment base + limit registers Segmentation + Paging Page Size 10 bit offset =\u003e 1 KB page size [2^10] 12 bit offset =\u003e 4 KB page size [2^12] In real world examples,\nLinux/x86 : 4 KB, 2MB, 1GB Solaris/Sparse: 8kB, 4MB, 2GB ||Large|Huge| |—-|—–| |page size|2 MB|1 GB| |offset bits|21 bits|30 bits| |reduction factor on page table size|x512|x1024|\nAdvantages\nlarger pages fewer page table entries, smaller page tables, more TLB hits Disadvantages\ninternal fragmentation =\u003e wastes memory Memory Allocation Memory allocator\ndetermines VA to PA mapping address translation, page tables =\u003e simply determine PA from VA and check validity/permsissions Kernel Level Allocators\nkernel state, static process state User Level Allocators\ndynamic process state (heap), malloc/free e.g. d/malloc, jemalloc, Hoard, tcmalloc Demand Paging Virtual Memory » Physical Memory virtual memory page is not always in physical memory physical page frame saved and restored to/from secondary storage Demand paging: pages swapped in/out of memory \u0026 a swap partition (e.g. on a disk) Original PA != PA after swapping if page is “pinned”, swapping is disabled When pages should be swapped? page(out) daemon when memory usage is above threshold when CPU usage is below threshold Which page should be swapped out? pages that won’t be used history based prediction Least Recently Used (LRU policy). Access bit tracks if page is referenced. page that don’t need to be written out Dirty bit to track if modified avoid non-swappable pages Checkpointing Failure and Recovery management technique periodically save process state failure may be unavoidable but can restart from checkpoint, so recovery would be faster Simple Approach pause and save Better Approach write-protect and copy everything at once copy diffs of dirties pages for incremental checkpoints rebuild from multiple diffs, or in background Checkpointing can also be used in other services:\nDebugging\nRewind-Replay rewind = restart from checkpoint gradually go back to earlier checkpoints until error is found Migration\ncontinue on another machine disaster recovery consolidation repeated checkpoints in a fast loop until pause and copy becomes acceptable (or unavoidable) Inter Process Communication Processes share memory data in shared messages Processes exchange messages message passing via sockets Requires synchronization mutex, waiting Inter Process Communication(IPC) is an OS supported mechanism for interaction among processes (coordination and communication)\nMessage Passing e.g. sockets, pips, msgs, queues Memory based IPC shared memory, memory mapped files Higher level semantics files, RPC Synchronization primitives Message Passing Send/Receive messages OS creates and maintains a channel buffer, FIFO queue OS provides interfaces to processes a port processes send/write messages to this port processes receive/read messages from this port Kernel required to establish communication perform each IPC operation send: system call + data copy receive: system call + data copy Request-response: 4x user/ kernel crossings + 4x data copies Advantages\nsimplicity : kernel does channel management and synchronization Disadvantages\nOverheads Forms of Message Passing IPC 1. Pipes Carry byte stream between 2 process e.g connect output from 1 process to input of another 2. Message queues Carry “messages” among processes OS management includes priorities, scheduling of message delivery APIs : Sys-V and POSIX 3. Sockets send() and recv() : pass message buffers socket() : create kernel level socket buffer associated neccessary kernel processing (TCP-IP,..) If different machines, channel between processes and network devices If same machine, bypass full protocol stack Shared Memory IPC read and write to shared memory region OS establishes shared channel between the processes physical pages mapped into virtual address space VA(P1) and VA(P2) map to same physical address VA(P1) != VA(P2) physical mempry doesn’t need to be contiguous APIs : SysV, POSIX, memory mapped files, Android ashmem Advantages\nSystem calls only for setup data copies potentially reduced (but not eliminated) Disdvantages\nexplicit synchronization communication protocol, shared buffer management programmer’s responsibility Which is better? Overheads for\nMessage Passing : must perform multiple copies Shared Memory : must establish all mappings among processes’ address space and shared memory pages Thus, it depends.\nCopy vs Map Goal for both is to transfer data from one into target saddress space\nCopy (Message Passing) Map (Shared Memory) CPU cycles to copy data to/from port CPU cycles to map memory into address space CPU to copy data to channel If channel setup once, use many times (good payoff) Can perform well for 1 time use Large Data: t(Copy) » t(Map) e.g. tradeoff exercised in Window “Local” Procedure Calls (LPC) Shared Memory and Synchronization Use threads accessing shared state in a single addressing space, but for process\nSynchronization method:\nmechanism supported by processing threading library (pthreads) OS supported IPC for sync Either method must coordinate\nno of concurrent access to shared segment when data is available and ready for consumption IPC Synchronization Message Queues Semaphores Implement “mutual exclusion” via send/receive OS supported synchronization construct binary construct (either allow process or not) Like mutex, if value = 0, stop; if value = 1, decrement(lock) and proceed Synchronization Waiting for other processes, so that they can continue working together\nmay repeatedly check to continue sync using spinlocks may wait for a signal to continue sync using mutexes and condition vatiables waiting hurts performance CPUs wste cycles for checking; cache effects Limitation of mutextes and condition variables Error prone/correctness/ease of use unlock wrong mutex, signal wrong condition variable Lack of expressive power helper variables for access or priority control Low-level support: hardware atmoic instructions\nSynchronization constructs Spinlocks (basic sync construct) Spinlock is like a mutex mutual exclusion lock and unlock(free) - but, lock == busy =\u003e spinning Semaphores common sync construct in OS kernels like a traffic light: Stop and Go like mutex, but more general Semaphore == integer value\non init assigned a max value (positive int) =\u003e max count on try(wait) if non-zero, decrement and proceed =\u003e counting semaphore if initialized with 1 semaphore == mutex(binary semaphore) on exit(post) increment Syncing different types of accesses Reader/Writer locks read (don't modify) write (always modify) shared access exclusive access RW locks specify type of access, then lock behaves accordingly Monitors (highlevel construct) shared resource entry resource possible condition variables On entry: lock, check On exit: unlock, check, signal More synchroniaztion constructs serializers path expressions barriers rendezvous points optimistic wait-free sync (RCU) [Read Copy Update] All need hardware support.\nNeed for hardware support Problem concurrent check/update on different CPUs can overlap Atomic instructions Critical section with hardware supported synchronization\nHardware specific test-and-set\nreturns(tests) original values and sets new-value!= 1 (busy) automatically first thread: test-and-set(lock) =\u003e 0 : free next ones: test-and-set(lock) =\u003e 1 busy reset lock to 1, but that’s okay + : Latency + : minimal (Atomic) + : Delay potentially min - : Contention processors go to memory on each spin - To reduce contention, introduce delay - Static(based on a fixed value) or Dynamic(backoff based, random delay) read-and-increment\ncompare-and-swap\nGuarantees atomicity mutual exclusion queue all concurrent instructions but one Shared Memory Multiprocessors Also called symmetric multiprocessors (SMP)\nCaches hide memory latency, “memory” further away due to contention no-write, write-through, write-back Cache Coherence # I/O Management Operating system\nHas protocols Interfaces for device I/O Has dedicated handlers Device drivers, interrupt handlers Decouple I/O details from core processing abstract I/O device detail from applications I/O Device Features Control registers (accessed by CPU) Command Data Transfers Status Microcontroller : device’s CPU On device memory Other logic e.g. analog to digital Device drivers per each device type responsible for device access management and control provided by device manufacturers per OS /version each OS standardizes interfaces device independence device diversity Types of devices Block e.g. disk read/write blocks of data direct access to arbitrary block Character e.g. keyboard get/put character Network devices OS representation of a device : special device file\nUNIX like systems:\n/dev tmpfs devfs Linux supports a number of pseudo “virtual” devices that provide special functionality to a system.\nCPU device interactions access device registers : memory load/store\nMemory mapped I/0 part of ‘host’ physical memory dedicated for device interactions Base Address Registers (BAR) I/O Port dedicated in low instructions for device access target device (I/0 port) and value in register Path from Device to CPU Interrupt Overhead: Interrupt handling steps +: Can be generated as soon as possible Polling Overhead: Delay or CPU overhead when convenient for OS Device access : Programmed I/O (PIO) No additional hardware support CPU “programs” the device via command registers data movement E.g. NIC(Network Interface Card) data = network packet Write command to request packet information Copy packet to data registers Repeat until packet sent E.g. 1500B packet; 8 byte registers or bus =\u003e 1(for bus command) + 188(for data) = 189 CPU store instructions\nDirect Memory Access (DMA) Relies on DMA controller CPU “programs” the device via command registers via DMA controls E.g. NIC (data = network packet) Write command to request packet information Configure DMA controller with in memory address and size of packet buffer E.g. 1500B packet; 8 byte registers or bus =\u003e 1(for bus command) + 1(for DMA configuration) = total 2 CPU store instructions. Less steps, but DMA configuration is more complex.\nFor DMAs\ndata buffer must be in physical memory until transfer completes pinning regions (non-swappable) Typical Device Access System call In-kernel stack Driver Invocation Device request configuration Device performs request OS bypass device registers/data directly available OS configures then gets out of the way “user level driver” in library OS retains coarse-grain control relies on device features sufficient registers demux capability What happens to a calling thread? Synchronous I/O operations process blocks Asynchronous I/O operations process continues Later, process checks and retrieves result OR process is notified that operation is completed and results are ready Block Device Stack Block device typical storage for files:\nprocesses use files =\u003e logical storage unit kernel file system (KFS) where how to find and access file OS specifies interface generic block layer OS standardized block interface Device driver Virtual File System Virtual File System Abstractions File : Elements on which the VFS operates File Descriptor : OS representation of file open, read, write, send file , lock, close inode : Persistent representation of file “index” list of all data blocks device, permissions, size dentry : Directory entry, corresponding to the single path component, dentry cache super block : file system specific information regarding the File System layout VFS on disk File : data blocks on disk inode : track file blocks also resides on disk in some block super block : overall map of disk blocks inode blocks data blocks free blocks Inodes Index of all disk blocks corresponding to a file\nFile : identified by inode inode : list of all blocks + other metadata +: Easy to perform sequential or random access\n-: Limit on file size\nInodes with indirect pointers Index of all disk blocks corresponding to a file Index contain: metadata pointers to blocks Direct pointer : Points to data block 1 KB per entry Indirect pointer : Points to block of pointers 256 KB per entry Double Indirect pointer : Points to block of block of pointers 64 MB per entry +: Small inode =\u003e large file size\n-: File access slowdown\nDisk access optimizations Reducing file access overheads\nCaching/buffering : reducenumber of disk accesses buffer cache in main menu read/write from cache periodically flush to disk - fsync() I/O scheduling : reduce disk head movement maximize sequential vs random access Prefetching : increases cache hits leverages locality Journaling/logging: reduce random access (ext3, ext4) “describe” write in log : block, offset, value.. periodically apply updates to proper disk locations # Virtualization Virtualization allows concurrent execution of multiple OSs and their applications on the same physical machine.\nVirtual resources : each OS thinks that ot “owns” hardware resources Virtual machine (VM) : OS + applications + virtual resources (guest domain) Virtualization layer : management of physical hardware (virtual machine monitor, hypervisor) Defining Virtual Machine A Virtual Machine is an efficient, isolated duplicate of the real machine.\nSupported by a Virtual Machine Monitor (VMM): provides environment essentially identical with the original machine programs show only minor decrease in speed at worst VMM is in complete control of the system resources VMM goals Fidelity Performance Safety and Isolation Virtualization advantages consolidation decrease cost, improve manageability migration availibility, reliability security, debugging, support for legacy OS Two main Virtualization Models: 1. Bare-metal or Hypervisor based (Type 1) VMM (hypervisor) manages all hardware resources abd supports execution of VMs privileged, secure VM to deal with devices (and other configuration and management tasks) Adopted by Xen(Opensource or Citriol Xen Server) and ESX (VMware) 1. Hosted (Type 2) Host owns all hardware Special VMM modle provides hardware interfaces to VMs and deals with VM context switching Virtualization requirements Present virtual platform interface to VMs virtualize CPU, memory, devices Provide isolation across VMs preemption, MMU for address translation and validation Protect guest OS from applications can’t run guest OS and applications at same protection level Protect VMs from guest OS can’t run guest OS and VMMs at same protection level Hardware protection levels Commodity hardware has more than two protection levels\nx86 has 4 protection levels (rings) ring 3 : lowest privilege (applications) ring 1 : OS ring 0 : highest privilege (hypervisor) and 2 protection modes non root : VMs ring 3 : apps ring 0 : OS root : ring 0 : hypervisor Process Virtualization (Trap-and-Emulate) Guest instruments executed directly by hardware for non-privileged operations : hardware speeds =\u003e efficiency for privileged operations : trap to hypervisor Hypervisor determines what needs to be done: if illegal operation : terminate VM if legal operation : emulate the behaviour the guest OS was expecting from the hardware Problems with Trap-and-Emulate 17 privileged information do not trao but fail silently Hypervisor doesn’t know, so it doesn’t try to change settings OS doesn’t know, so assumes change was successful Binary Translation Goal : Full Virtualization i.e. guest OS is not modified\nApproach : Dynamic Binary Translation\nInspect code blocks to be executed If needed, translate to alternate instruction sequence e.g. to emulate desired behaviour, possibly avoid traps Otherwise run at hardware speeds cache translated blocks to ammortize translation costs Paravirtualization Goal : Performance; give up on modified guest OSs\nApproach : Paravirtualization : modify guest OSs so that\nit knows it is running virtualized it makes explicit calls to hyperisor (hypercalls) hypercalls (~ system calls) package context information specify desired hypercall trap to VMM Xen : opensource hypervisor Memory virtualization Full virtualization all guests expect contiguous physical memory starting at 0 virtual vs physical vs machine addresses and page frame numbers still leverages hardware (MMU, TLB..) Option 1 guest page table : VA =\u003e PA hypervisor : PA =\u003e MA too expensive! Option 2 guest page tables : VA =\u003e PA hypervisor shadow PT : VA =\u003e MA hypervisor maintains consistence e.g. invalidate on context switch, write protect guest PT to track new mappings Paravirtualized guest aware of virtualization no longer strict requirement on contiguous physical memory starting at 0 explicitly registers page tables with hypervisor can “batch” page tables updates to reduce VM exits other optimazations Overheads eliminated or reduced on newer platforms\nDevice Virtualization For CPUs and Memory less diversity, Intruction-Set-Architecture(ISA) level Standardization of interface For Devices high diversity lack of standard specification of device interface and behaviour 3 key models for Device Virtualization: 1. Pass through model Approach: VMM-level-driver configures device access permissions\nAdvantages\nVM provided with exclusive and direct (VMM bypass) access to the device Disadvantages\nDevice sharing difficult VMM must have exact type of device as what VM expects VM migration tricky 2. Hypervisor - Direct model Approach:\nVMM interrupts all device accesses Emulate device operations translate to generic I/O operations traverse VMM-resident I/O stack invoke VMM-resident driver Advantages\nVM decoupled from physical device Sharing, migration, dealing with device specifics Disadvantages\nLatency of device operations Device driver ecosystem complexities in Hypervisor 3. Split Device-Driver model Approach:\nDevice access control split between Emulate device operations front-end driver in guest VM (device API) back-end driver in service VM (or Host) modified guest drivers i.e. limited to paravirtualized guests Advantages\nEliminate emulation overhead Allow for better management of shared devices Remote Procedure Calls Example : GetFile App\nClient Server Create and init sockets Allocate and populate buffers Include ‘protocol’ info GetFile, size Copy data into buffers filename, file common steps related to remote IPC Remote Procedure Calls (RPC) Intended to simplify the development of cross address space and cross machine interactions + Higher-level interface for data movement and communication\n+ Error handling\n+ Hiding complexities of cross machine interactions\nRPC requirements Client/Server interactions Procedure Call Interface =\u003e RPC sync call semantics Type checking error handling packet bytes interpretation Cross machine conversion e.g. big/little endian Higher level protocol access control, fault tolerance, different transport protocols Structure of RPC RPC Steps: (-1.) register : server registers procedure, arg types, location\n(0.) bind : client finds and binds to desired server\ncall : client make RPC call; control passed to stub, client code blocks marshal : client stub “marshals” args (serialize args into buffer) send : client sends message to server receive : server receives message; passes message to server stub; access control unmarshal : server stub “unmarshals” args (extract args from buffer) actual call : server stub calls local procedure implementation result : server performs operation and computes result of RPC operation (same on return \u003c=)\nInterface definition Language (IDL) Used to describe the interface the server expects procedure name, args, 2 result types version number RPC can use IDL that is\nLanguage agnostic XDR in SunRPC Language specific Java in JavaRMI Marshalling Unmarshalling Marshalling/Unmarshalling routines are provided by RPC system compiler.\nBinding and Registry Client determines which server to connect to? service name. version number how to connect to that server? IP address, network protocol Registry : database of available services search for service name to find server(which) and contact details(how) distributed any RPC service can register machine-specific for services running on same machine clients must know machine addresses registry provides port number needed for connection Who can provide a service? lookup registry for image processing What services do they provide? compress/filter.. version number =\u003e IDL How will they ship package? TCP / UDP -\u003e registry Pointers Procedure interface : foo(int,int) in Local Calls : foo(x,y) =\u003e okay in Remote Calls : foo(x,y) =\u003e ? here, y points to location in caller address space\nSolutions: No pointers Serialize pointers; copy referenced (“points to”) data structure to send buffer Handling Partial Failures Special RPC error notification (signal, exception..) Catch all possible ways in which RPC can (partially) fail RPC Design choice Binding =\u003e How to find the server IDL =\u003e How to talk to server; how to package data Pointers as args =\u003e Disallow or serialize pointer data Partial failures =\u003e Special error notifications Distributed File Systems Accessed via well defined interface access via Virtual File Systems Focus on consistent state tracking state, file update, cache coherence Mixed distribution models possible replicates vs partitioned, peer-like systems DFS models Client Server on different machines File server distributed on multiple machines replicated (each server : all files) partitioned (each server : parts of files) both (files partitioned, each partition replicates) Files stored on and served from all machines (peers) blurred distinction between clients and servers Remote File Service : Extremes Extreme1 : Upload/Download like FTP, SVN + local read/writes at client - entire file download/upload evn for small accesses - server gives up contro; Extreme2 : True Remote File Access Every access to remote file, nothing done locally + file access centralized, easy to reason about consistency - every file operation pays network cost, limits server scalablity Remote File Service : A compromise A more practical Remote File access (with Caching)\nAllow clients to store parts of files locally (blocks) + low latency on file operations + server load reduces =\u003e more scalable Force clients to interact with server (frequently) + server has insights into what clients are doing + server has control into which accesses can be permitted =\u003e easier to maintain consistency - server more complex, requires different file sharing semantics Stateless vs Stateful File server Stateless Stateful Keeps no state; Okay with extreme models, but can’t support ‘practical’ model Keeps client state needed for ‘practical’ model to track what is cached/accessed - Can’t support caching and consistency management + Can support locking, caching, incremental operations - Every request self-contained. =\u003e more bits transferred - Overheads to maintain state and consistency. Depends on caching mechanism and consistency protocol. + No resources are used on server side (CPU, MM). On failure just restart - On failure, need checkpoining and recovery mechanisms Caching state in a DFS Locally clients maintain portion of state (e.g. file blocks) Locally clients perform operations on cached state (e.g. open/read/write) requires coherent mechanisms System How When SMP Write-update/Write-invalidate On write DFS Client/Server-driven On demand, periodically, on open.. Files or File blocks can be (with 1 server and multiple clients) cached in:\nin client memory on client storage device (HDD/SDD) in buffer cache in memory on server (usefulness will depend on client load, request interleaving) File Sharing Semantics in DFS\nSession semantics (between open-close =\u003e Session)\nwrite-back on close(), update on open() easy to reason, but may be insufficient Periodic updates\nclient writes-back periodically clients have a “lease” on cached data (not exclusively necessary) servers invalidates periodically =\u003e provides biunds on “inconsistency” augment with flush()/sync() API Immutable files =\u003e never modify, new files created\nTransactions =\u003e all changes atomic\nReplication vs Partitioning Replication Partitioning Each machine holds all files Each machine has subset of files Advantages Load balancing, availibility, fault tolerance Availibility vs single server DFS;\nScalability with file system size;\nsingle file writes simpler Disadvantages Write becomes more complex\n- Synchronous to all\n- or, write to one, then propagate to others\nreplicas must be reconciled e.g. Voting On failure, lose portion of data\nload balancing harder, if not balanced, then hot-spots possible Can combine both techniques Replicate each partition! Distributed Shared Memory Must decide placement place memory (pages) close to relevant processes Must decide migration when to copy memory (pages) from remote to local Must decide sharing rules ensure memory generations are properly ordered “Peer” Distribution Applications Each node “owns” state provide service all nodes are “peers”. Examples: Big-data analytics, web searches, context sharing or distributed shared memory (DSM)\nDistributed Shared Memory (DSM) DSM is a service that manages memory accross multiple nodes so that applications that are running on top will have an illusion that they are running on a shared memory.\nEach node “owns” state =\u003e memory provide service memory read/writes from any nodes consistency protocols permits scaling beyond single machine memory limits more “shared” memory at lower cost slower overall memory access commodity interconnect technologies support this RDMA(Remote Direct Memory Access) Hardware vs Software DSM Hardware-supported (expensive!) relies on interconnect OS manages larger physical memory NIC(Network Interface Cards) translate remote memory accesses to messages NICs involved in all aspects of memory management; support atomics.. Software supported everything done by software OS,or language runtime Hybrid (Software tasks in Hardware) DSM implementations prefetch pages address translation (easier done in hardware) triggering invalidations (easier done in hardware) DSM Design : Sharing Granularity cache line granularity? overheads too high for DSM variable granularity [N] page granularity [Y] (OS level) object granularity [Y] (Language runtime) beware of false sharing E.g. x and y shared on same page What types of applications use DSM? Application access algorithm\nSingle reader/ single writer (SRSW) Multiple readers/ single writer (MRSW) Multiple reader/ Multiple writers (MRMW) Performance considerations DSM performance metric == access latency Achieving low latency through Migration makes sense for SRSW requires data movement Replication (caching) more general requires consistency management Hence, migration is okay for SRSW but not for all. Caching and Replication Copies of data to incerease data access for many concurrent writes, overheads too high but stil generally better than Migration Consistency Management In SMP write invalidate write update coherence operations triggered in each write overhead too high Push invalidations when data is written to Proactive Eager Pessimistic Pull modifications information periodically on demand (reactive) lazy optimistic when these methods get triggered depends on the consistency model for the shared state DSM architecture (page-based, OS-supported) Page-based DSM architecture distributed nodes, each with own local memory contribution pool of pages from all nodes each page has IO (“home” node), page frame number if MRMW need local caches for performances (latency) “home” or “manager” node drives coherence operations all nodes responsible for part if distributed memory (state) management Home node keeps state: page accessed, modifications, caching enabled/disabled, locked.. Current owner owner may not be equal to home node Explicit replicas for load balancing, performance, or reliability home, manager node controls memory DSM metadata Implementing DSMs Problem : DSM must intercept access to DSM state to send remote messages requesting access to trigger coherence messages overheads should be avoided for local non-shared state (pages) dynamically engage and disengage DSM when necessary Solution : Use hardware MMU support! trap in OS if mapping invalid or access denied remote address mapping -\u003e trap and pass to DSM to send message cached content -\u003e trap and pass to DSM to perform memory coherence operations other MMU information useful (e.g. Dirty page) Consistency model Agreement between memory (state) and upper software layers Memory behaves correctly if and only if software follows specific rules Memory (state) guarantees to behave correctly access ordering propagation/ visibility of updates Our notation R_m1(X) =\u003e X was read from memory location m1 W_m1(Y) =\u003e Y was written to memory location m1 Strict Consistency Strict Consistency =\u003e updates visible everywhere immediately\nIn practice Even on single SMP no guarantees on order without extra locking and synchronization in DS, latency and message reorder make this even harder Hence almost impossible to guarantee strict consistency Sequential Consistency Sequential consistency =\u003e\nmemory updates from different processors may be arbitrarily interleaved All processes will see the same interleaving Operations from the same process always appearin order they were issued Causal Consistency For writes not causally related, “concurrent” writes doesnt gurantee. Don’t permit arbitrary ordering from same process writer Weak Consistency Use of synchronization Synchronization point =\u003e operations that are available (R,W,Sync) all updates prior to a sync point will be visible no guarantee what happens in between + limit data movement of coherence operations\n- maintain extra state for additional operations\nVariations: Single sync operation (sync) Seperate sync per surface of state (page) Seperate “entry/acquire” vs “exit/release” operations ","wordCount":"8584","inLanguage":"en","image":"https://res.cloudinary.com/samirpaul/image/upload/w_1100,c_fit,co_rgb:FFFFFF,l_text:Arial_75_bold:Operating System Notes For Placement/og-image.webp","datePublished":"2023-06-20T00:00:00Z","dateModified":"2023-06-20T00:00:00Z","author":{"@type":"Person","name":"Samir Paul"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://samirpaulb.github.io/posts/operating-system-notes-for-placement/"},"publisher":{"@type":"Organization","name":"Samir Paul","logo":{"@type":"ImageObject","url":"https://samirpaulb.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://samirpaulb.github.io/ accesskey=h title="Samir Paul (Alt + H)">Samir Paul</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://samirpaulb.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://samirpaulb.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://samirpaulb.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://samirpaulb.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://samirpaulb.github.io/posts/>Blog Posts</a></div><h1 class="post-title entry-hint-parent">Operating System Notes For Placement</h1><div class=post-meta><span title='2023-06-20 00:00:00 +0000 UTC'>June 20, 2023</span>&nbsp;·&nbsp;41 min&nbsp;·&nbsp;8584 words&nbsp;·&nbsp;Samir Paul</div></header><figure class=entry-cover><img loading=eager src=https://res.cloudinary.com/samirpaul/image/upload/w_1100,c_fit,co_rgb:FFFFFF,l_text:Arial_75_bold:Operating%20System%20Notes%20For%20Placement/og-image.webp alt="Operating System Notes For Placement"></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#operating-systems-overview aria-label="Operating Systems Overview">Operating Systems Overview</a><ul><ul><li><a href=# aria-label="Download PDF Notes➥">Download PDF Notes➥</a></li></ul><li><a href=#what-is-an-operating-system aria-label="What is an Operating System?">What is an Operating System?</a></li><li><a href=#operating-system-definition aria-label="Operating System definition:">Operating System definition:</a></li><li><a href=#operating-system-examples aria-label="Operating System examples:">Operating System examples:</a></li><li><a href=#os-elements aria-label="OS Elements">OS Elements</a><ul><ul><li><a href=#example- aria-label="Example :">Example :</a></li></ul></ul></li><li><a href=#os-design-principles aria-label="OS Design Principles">OS Design Principles</a></li><li><a href=#user-kernel-protection-boundary aria-label="User/ Kernel Protection Boundary">User/ Kernel Protection Boundary</a></li><li><a href=#system-call-flowcart aria-label="System call Flowcart">System call Flowcart</a></li><li><a href=#basic-os-services aria-label="Basic OS services">Basic OS services</a></li><li><a href=#linux-system-calls aria-label="Linux System Calls">Linux System Calls</a></li><li><a href=#linux-architecture aria-label="Linux Architecture">Linux Architecture</a></li></ul></li><li><a href=#process-and-process-management aria-label="Process and Process Management">Process and Process Management</a><ul><li><a href=#what-does-a-process-look-like aria-label="What does a process look like?">What does a process look like?</a><ul><li><a href=#type-of-state aria-label="Type of state">Type of state</a></li></ul></li><li><a href=#how-does-the-os-know-what-a-process-is-doing aria-label="How does the OS know what a process is doing?">How does the OS know what a process is doing?</a></li><li><a href=#process-control-block-pcb aria-label="Process Control Block (PCB)">Process Control Block (PCB)</a></li><li><a href=#how-is-pcb-used- aria-label="How is PCB used ?">How is PCB used ?</a></li><li><a href=#context-switch aria-label="Context Switch">Context Switch</a></li><li><a href=#process-lifecycle aria-label="Process Lifecycle">Process Lifecycle</a></li><li><a href=#process-creation aria-label="Process Creation">Process Creation</a><ul><ul><li><a href=#mechanisms aria-label=Mechanisms:>Mechanisms:</a></li></ul></ul></li><li><a href=#what-is-the-role-of-cpu-scheduler aria-label="What is the role of CPU scheduler?">What is the role of CPU scheduler?</a></li><li><a href=#scheduling-design-decisions aria-label="Scheduling design decisions">Scheduling design decisions</a></li><li><a href=#io aria-label=I/O>I/O</a></li><li><a href=#can-process-interact aria-label="Can process interact?">Can process interact?</a><ul><ul><li><a href=#inter-process-communication aria-label="Inter Process communication:">Inter Process communication:</a></li><li><a href=#1-message-passing-ipc aria-label="1. Message Passing IPC">1. Message Passing IPC</a></li><li><a href=#2-shared-memory-ipc aria-label="2. Shared Memory IPC">2. Shared Memory IPC</a></li></ul></ul></li></ul></li><li><a href=#threads-and-concurrency aria-label="Threads and Concurrency">Threads and Concurrency</a><ul><li><a href=#process-vs-thread aria-label="Process vs Thread">Process vs Thread</a></li><li><a href=#why-are-threads-useful aria-label="Why are threads useful?">Why are threads useful?</a></li><li><a href=#what-do-we-need-to-support-threads aria-label="What do we need to support threads?">What do we need to support threads?</a></li><li><a href=#concurrency-control-and-coordination aria-label="Concurrency control and Coordination">Concurrency control and Coordination</a></li><li><a href=#threads-and-threads-creation aria-label="Threads and Threads creation">Threads and Threads creation</a><ul><li><a href=#example aria-label=Example:>Example:</a></li></ul></li><li><a href=#mutual-exclusion aria-label="Mutual Exclusion">Mutual Exclusion</a></li><li><a href=#producer-consumer-problem aria-label="Producer Consumer problem">Producer Consumer problem</a></li><li><a href=#readers--writer-problem aria-label="Readers / Writer problem">Readers / Writer problem</a></li><li><a href=#avoiding-common-mistakes aria-label="Avoiding common mistakes">Avoiding common mistakes</a></li><li><a href=#spuriousunnecessary-wake-ups aria-label="Spurious(Unnecessary) Wake ups">Spurious(Unnecessary) Wake ups</a></li><li><a href=#deadlocks aria-label=Deadlocks>Deadlocks</a><ul><li><a href=#how-to-avoid-this aria-label="How to avoid this?">How to avoid this?</a></li></ul></li><li><a href=#kernel-vs-user-level-threads aria-label="Kernel vs User level Threads">Kernel vs User level Threads</a><ul><ul><li><a href=#1-one-to-one-model aria-label="1. One to One model:">1. One to One model:</a></li><li><a href=#2-many-to-one-model aria-label="2. Many to One model:">2. Many to One model:</a></li><li><a href=#3-many-to-many-model aria-label="3. Many to Many model:">3. Many to Many model:</a></li></ul></ul></li><li><a href=#multithreading-patterns aria-label="Multithreading patterns">Multithreading patterns</a><ul><li><a href=#example-1 aria-label=Example:>Example:</a></li></ul></li><li><a href=#pthreads aria-label=PThreads>PThreads</a><ul><li><a href=#compiling-pthreads aria-label="Compiling PThreads">Compiling PThreads</a></li><li><a href=#pthread-mutexes aria-label="PThread mutexes">PThread mutexes</a></li><li><a href=#safety-tips aria-label="Safety tips">Safety tips</a></li></ul></li><li><a href=#thread-design-considerations aria-label="Thread Design Considerations">Thread Design Considerations</a><ul><li><a href=#kernel-vs-user-level-threads-1 aria-label="Kernel vs User Level Threads">Kernel vs User Level Threads</a></li><li><a href=#thread-related-data-structures aria-label="Thread related data structures">Thread related data structures</a></li><li><a href=#hard-vs-light-process-states aria-label="Hard vs Light Process states">Hard vs Light Process states</a><ul><li><a href=#rationale-for-multiple-data-structures aria-label="Rationale for Multiple Data Structures:">Rationale for Multiple Data Structures:</a></li></ul></li></ul></li><li><a href=#comparison-of-interrupts-and-signals aria-label="Comparison of Interrupts and Signals">Comparison of Interrupts and Signals</a><ul><li><a href=#interrupts aria-label=Interrupts>Interrupts</a></li><li><a href=#signals aria-label=Signals>Signals</a><ul><li><a href=#handlers--actions aria-label="Handlers / Actions">Handlers / Actions</a></li></ul></li><li><a href=#why-disable-interrupts-or-signals aria-label="Why disable Interrupts or Signals">Why disable Interrupts or Signals</a></li><li><a href=#types-of-signals aria-label="Types of Signals">Types of Signals</a></li><li><a href=#handling-interrupts-as-threads aria-label="Handling interrupts as threads">Handling interrupts as threads</a></li><li><a href=#threads-and-signal-handling aria-label="Threads and Signal Handling">Threads and Signal Handling</a></li></ul></li><li><a href=#multi-processing-vs-multi-threading aria-label="Multi-processing vs Multi-threading">Multi-processing vs Multi-threading</a><ul><li><a href=#multi-processing-mp aria-label="Multi-Processing (MP)">Multi-Processing (MP)</a></li><li><a href=#multi-threading-mp aria-label="Multi-Threading (MP)">Multi-Threading (MP)</a></li></ul></li><li><a href=#event-driven-model aria-label="Event Driven model">Event Driven model</a><ul><li><a href=#concurrent-execution-in-event-driven-models aria-label="Concurrent execution in Event-driven models">Concurrent execution in Event-driven models</a></li><li><a href=#asynchronous-io-operations aria-label="Asynchronous I/O operations">Asynchronous I/O operations</a></li><li><a href=#asymmetric-multi-process-event-driven-model-amped--amted aria-label="Asymmetric Multi-Process Event Driven model (AMPED & AMTED)">Asymmetric Multi-Process Event Driven model (AMPED & AMTED)</a></li></ul></li></ul></li><li><a href=#scheduling aria-label=Scheduling>Scheduling</a><ul><li><a href=#cpu-scheduler aria-label="CPU Scheduler">CPU Scheduler</a><ul><li><a href=#run-to-completion-scheduling aria-label="&ldquo;Run-to-completion&rdquo; Scheduling">&ldquo;Run-to-completion&rdquo; Scheduling</a></li></ul></li><li><a href=#scheduling-algorithms aria-label="Scheduling algorithms:">Scheduling algorithms:</a><ul><li><a href=#1-first-come-first-serve-fcfs aria-label="1. First Come First Serve (FCFS)">1. First Come First Serve (FCFS)</a></li><li><a href=#2-shortest-job-first-sjf aria-label="2. Shortest Job First (SJF)">2. Shortest Job First (SJF)</a></li><li><a href=#preemptive-scheduling aria-label="Preemptive Scheduling">Preemptive Scheduling</a></li><li><a href=#priority-scheduling aria-label="Priority Scheduling">Priority Scheduling</a></li><li><a href=#3-round-robin-scheduling aria-label="3. Round-Robin Scheduling">3. Round-Robin Scheduling</a></li><li><a href=#4-shortest-remaining-time-first-srtf aria-label="4. Shortest Remaining Time First (SRTF)">4. Shortest Remaining Time First (SRTF)</a><ul><li><a href=#timeslicing aria-label=Timeslicing>Timeslicing</a></li><li><a href=#how-long-should-a-timeslice-be-be aria-label="How long should a timeslice be be?">How long should a timeslice be be?</a></li></ul></li><li><a href=#for-cpu-bound-tasks aria-label="For CPU bound tasks:">For CPU bound tasks:</a></li><li><a href=#for-io-bound-tasks aria-label="For I/O bound tasks:">For I/O bound tasks:</a></li><li><a href=#summary aria-label=Summary>Summary</a></li></ul></li></ul></li><li><a href=#memory-management aria-label="Memory Management">Memory Management</a><ul><li><a href=#memory-management-goals aria-label="Memory Management Goals">Memory Management Goals</a><ul><ul><li><a href=#virtual-vs-physical-memory aria-label="Virtual vs Physical memory">Virtual vs Physical memory</a></li><li><a href=#page-based-memory-management aria-label="Page-based Memory Management">Page-based Memory Management</a></li><li><a href=#segment-based-memory-management aria-label="Segment-based Memory Management">Segment-based Memory Management</a></li></ul></ul></li><li><a href=#hardware-support aria-label="Hardware Support">Hardware Support</a><ul><li><a href=#memory-management-unit-mmu aria-label="Memory Management Unit (MMU)">Memory Management Unit (MMU)</a></li><li><a href=#registers aria-label=Registers>Registers</a></li><li><a href=#cache aria-label=Cache>Cache</a></li><li><a href=#translation aria-label=Translation>Translation</a></li></ul></li><li><a href=#page-tables aria-label="Page Tables">Page Tables</a></li><li><a href=#page-table-entry-pte aria-label="Page Table Entry (PTE)">Page Table Entry (PTE)</a><ul><ul><li><a href=#flags aria-label=Flags>Flags</a></li></ul></ul></li><li><a href=#page-table-entry-on-x86 aria-label="Page Table Entry on x86">Page Table Entry on x86</a><ul><ul><li><a href=#flags-1 aria-label=Flags>Flags</a></li></ul></ul></li><li><a href=#page-faults aria-label="Page faults">Page faults</a></li><li><a href=#page-table-size aria-label="Page Table Size">Page Table Size</a></li><li><a href=#hierarchical-page-tables aria-label="Hierarchical Page Tables">Hierarchical Page Tables</a><ul><ul><li><a href=#address-split aria-label="Address split:">Address split:</a></li></ul><li><a href=#tradeoffs-of-multilevel-page-tables aria-label="Tradeoffs of Multilevel Page Tables">Tradeoffs of Multilevel Page Tables</a></li></ul></li><li><a href=#overheads-of-address-translation aria-label="Overheads of Address Translation">Overheads of Address Translation</a></li><li><a href=#page-table-cache aria-label="Page Table Cache">Page Table Cache</a><ul><ul><li><a href=#translation-lookaside-buffer aria-label="Translation Lookaside Buffer">Translation Lookaside Buffer</a></li></ul><li><a href=#inverted-page-tables aria-label="Inverted Page Tables">Inverted Page Tables</a></li><li><a href=#hashing-page-tables aria-label="Hashing Page Tables">Hashing Page Tables</a></li></ul></li><li><a href=#segmentation aria-label=Segmentation>Segmentation</a><ul><ul><li><a href=#segmentation--paging aria-label="Segmentation + Paging">Segmentation + Paging</a></li></ul></ul></li><li><a href=#page-size aria-label="Page Size">Page Size</a></li><li><a href=#memory-allocation aria-label="Memory Allocation">Memory Allocation</a></li><li><a href=#demand-paging aria-label="Demand Paging">Demand Paging</a><ul><li><a href=#demand-paging-1 aria-label="Demand paging:">Demand paging:</a><ul><li><a href=#when-pages-should-be-swapped aria-label="When pages should be swapped?">When pages should be swapped?</a></li><li><a href=#which-page-should-be-swapped-out aria-label="Which page should be swapped out?">Which page should be swapped out?</a></li></ul></li></ul></li><li><a href=#checkpointing aria-label=Checkpointing>Checkpointing</a><ul><ul><li><a href=#simple-approach aria-label="Simple Approach">Simple Approach</a></li><li><a href=#better-approach aria-label="Better Approach">Better Approach</a></li></ul></ul></li></ul></li><li><a href=#inter-process-communication-1 aria-label="Inter Process Communication">Inter Process Communication</a><ul><li><a href=#message-passing aria-label="Message Passing">Message Passing</a><ul><li><a href=#forms-of-message-passing-ipc aria-label="Forms of Message Passing IPC">Forms of Message Passing IPC</a><ul><li><a href=#1-pipes aria-label="1. Pipes">1. Pipes</a></li><li><a href=#2-message-queues aria-label="2. Message queues">2. Message queues</a></li><li><a href=#3-sockets aria-label="3. Sockets">3. Sockets</a></li></ul></li></ul></li><li><a href=#shared-memory-ipc aria-label="Shared Memory IPC">Shared Memory IPC</a></li><li><a href=#which-is-better aria-label="Which is better?">Which is better?</a></li><li><a href=#copy-vs-map aria-label="Copy vs Map">Copy vs Map</a></li><li><a href=#shared-memory-and-synchronization aria-label="Shared Memory and Synchronization">Shared Memory and Synchronization</a><ul><li><a href=#ipc-synchronization aria-label="IPC Synchronization">IPC Synchronization</a></li></ul></li></ul></li><li><a href=#synchronization aria-label=Synchronization>Synchronization</a><ul><li><a href=#limitation-of-mutextes-and-condition-variables aria-label="Limitation of mutextes and condition variables">Limitation of mutextes and condition variables</a></li><li><a href=#synchronization-constructs aria-label="Synchronization constructs">Synchronization constructs</a></li><li><a href=#syncing-different-types-of-accesses aria-label="Syncing different types of accesses">Syncing different types of accesses</a><ul><li><a href=#readerwriter-locks aria-label="Reader/Writer locks">Reader/Writer locks</a></li><li><a href=#monitors-highlevel-construct aria-label="Monitors (highlevel construct)">Monitors (highlevel construct)</a></li><li><a href=#more-synchroniaztion-constructs aria-label="More synchroniaztion constructs">More synchroniaztion constructs</a></li></ul></li><li><a href=#need-for-hardware-support aria-label="Need for hardware support">Need for hardware support</a><ul><li><a href=#atomic-instructions aria-label="Atomic instructions">Atomic instructions</a><ul><li><a href=#hardware-specific aria-label="Hardware specific">Hardware specific</a></li><li><a href=#guarantees aria-label=Guarantees>Guarantees</a></li></ul></li><li><a href=#shared-memory-multiprocessors aria-label="Shared Memory Multiprocessors">Shared Memory Multiprocessors</a></li><li><a href=#cache-coherence aria-label="Cache Coherence">Cache Coherence</a></li></ul></li><li><a href=#io-device-features aria-label="I/O Device Features">I/O Device Features</a></li><li><a href=#device-drivers aria-label="Device drivers">Device drivers</a></li><li><a href=#types-of-devices aria-label="Types of devices">Types of devices</a></li><li><a href=#cpu-device-interactions aria-label="CPU device interactions">CPU device interactions</a></li><li><a href=#path-from-device-to-cpu aria-label="Path from Device to CPU">Path from Device to CPU</a></li><li><a href=#device-access--programmed-io-pio aria-label="Device access : Programmed I/O (PIO)">Device access : Programmed I/O (PIO)</a></li><li><a href=#direct-memory-access-dma aria-label="Direct Memory Access (DMA)">Direct Memory Access (DMA)</a></li><li><a href=#typical-device-access aria-label="Typical Device Access">Typical Device Access</a><ul><li><a href=#os-bypass aria-label="OS bypass">OS bypass</a></li></ul></li><li><a href=#what-happens-to-a-calling-thread aria-label="What happens to a calling thread?">What happens to a calling thread?</a></li><li><a href=#block-device-stack aria-label="Block Device Stack">Block Device Stack</a></li><li><a href=#virtual-file-system aria-label="Virtual File System">Virtual File System</a><ul><li><a href=#virtual-file-system-abstractions aria-label="Virtual File System Abstractions">Virtual File System Abstractions</a></li><li><a href=#vfs-on-disk aria-label="VFS on disk">VFS on disk</a></li><li><a href=#inodes aria-label=Inodes>Inodes</a></li><li><a href=#inodes-with-indirect-pointers aria-label="Inodes with indirect pointers">Inodes with indirect pointers</a></li></ul></li><li><a href=#disk-access-optimizations aria-label="Disk access optimizations">Disk access optimizations</a></li><li><a href=#defining-virtual-machine aria-label="Defining Virtual Machine">Defining Virtual Machine</a></li><li><a href=#vmm-goals aria-label="VMM goals">VMM goals</a></li><li><a href=#virtualization-advantages aria-label="Virtualization advantages">Virtualization advantages</a></li><li><a href=#two-main-virtualization-models aria-label="Two main Virtualization Models:">Two main Virtualization Models:</a><ul><li><a href=#1-bare-metal-or-hypervisor-based-type-1 aria-label="1. Bare-metal or Hypervisor based (Type 1)">1. Bare-metal or Hypervisor based (Type 1)</a></li><li><a href=#1-hosted-type-2 aria-label="1. Hosted (Type 2)">1. Hosted (Type 2)</a></li></ul></li><li><a href=#virtualization-requirements aria-label="Virtualization requirements">Virtualization requirements</a></li><li><a href=#hardware-protection-levels aria-label="Hardware protection levels">Hardware protection levels</a></li><li><a href=#process-virtualization-trap-and-emulate aria-label="Process Virtualization (Trap-and-Emulate)">Process Virtualization (Trap-and-Emulate)</a></li><li><a href=#problems-with-trap-and-emulate aria-label="Problems with Trap-and-Emulate">Problems with Trap-and-Emulate</a></li><li><a href=#binary-translation aria-label="Binary Translation">Binary Translation</a></li><li><a href=#paravirtualization aria-label=Paravirtualization>Paravirtualization</a></li><li><a href=#memory-virtualization aria-label="Memory virtualization">Memory virtualization</a></li><li><a href=#device-virtualization aria-label="Device Virtualization">Device Virtualization</a><ul><ul><li><a href=#3-key-models-for-device-virtualization aria-label="3 key models for Device Virtualization:">3 key models for Device Virtualization:</a></li></ul><li><a href=#1-pass-through-model aria-label="1. Pass through model">1. Pass through model</a></li><li><a href=#2-hypervisor---direct-model aria-label="2. Hypervisor - Direct model">2. Hypervisor - Direct model</a></li><li><a href=#3-split-device-driver-model aria-label="3. Split Device-Driver model">3. Split Device-Driver model</a></li></ul></li></ul></li><li><a href=#remote-procedure-calls aria-label="Remote Procedure Calls">Remote Procedure Calls</a><ul><ul><ul><li><a href=#remote-procedure-calls-rpc aria-label="Remote Procedure Calls (RPC)">Remote Procedure Calls (RPC)</a></li></ul></ul><li><a href=#rpc-requirements aria-label="RPC requirements">RPC requirements</a></li><li><a href=#structure-of-rpc aria-label="Structure of RPC">Structure of RPC</a></li><li><a href=#rpc-steps aria-label="RPC Steps:">RPC Steps:</a></li><li><a href=#interface-definition-language-idl aria-label="Interface definition Language (IDL)">Interface definition Language (IDL)</a></li><li><a href=#marshalling aria-label=Marshalling>Marshalling</a></li><li><a href=#unmarshalling aria-label=Unmarshalling>Unmarshalling</a></li><li><a href=#binding-and-registry aria-label="Binding and Registry">Binding and Registry</a></li><li><a href=#pointers aria-label=Pointers>Pointers</a></li><li><a href=#handling-partial-failures aria-label="Handling Partial Failures">Handling Partial Failures</a></li><li><a href=#rpc-design-choice aria-label="RPC Design choice">RPC Design choice</a></li></ul></li><li><a href=#distributed-file-systems aria-label="Distributed File Systems">Distributed File Systems</a><ul><li><a href=#dfs-models aria-label="DFS models">DFS models</a></li><li><a href=#remote-file-service--extremes aria-label="Remote File Service : Extremes">Remote File Service : Extremes</a></li><li><a href=#remote-file-service--a-compromise aria-label="Remote File Service : A compromise">Remote File Service : A compromise</a></li><li><a href=#stateless-vs-stateful-file-server aria-label="Stateless vs Stateful File server">Stateless vs Stateful File server</a></li><li><a href=#caching-state-in-a-dfs aria-label="Caching state in a DFS">Caching state in a DFS</a></li></ul></li><li><a href=#replication-vs-partitioning aria-label="Replication vs Partitioning">Replication vs Partitioning</a></li><li><a href=#distributed-shared-memory aria-label="Distributed Shared Memory">Distributed Shared Memory</a><ul><li><a href=#peer-distribution-applications aria-label="&ldquo;Peer&rdquo; Distribution Applications">&ldquo;Peer&rdquo; Distribution Applications</a></li><li><a href=#distributed-shared-memory-dsm aria-label="Distributed Shared Memory (DSM)">Distributed Shared Memory (DSM)</a></li><li><a href=#hardware-vs-software-dsm aria-label="Hardware vs Software DSM">Hardware vs Software DSM</a></li><li><a href=#dsm-design--sharing-granularity aria-label="DSM Design : Sharing Granularity">DSM Design : Sharing Granularity</a></li><li><a href=#what-types-of-applications-use-dsm aria-label="What types of applications use DSM?">What types of applications use DSM?</a></li><li><a href=#performance-considerations aria-label="Performance considerations">Performance considerations</a></li><li><a href=#consistency-management aria-label="Consistency Management">Consistency Management</a></li><li><a href=#dsm-architecture-page-based-os-supported aria-label="DSM architecture (page-based, OS-supported)">DSM architecture (page-based, OS-supported)</a></li><li><a href=#dsm-metadata aria-label="DSM metadata">DSM metadata</a></li><li><a href=#implementing-dsms aria-label="Implementing DSMs">Implementing DSMs</a></li><li><a href=#consistency-model aria-label="Consistency model">Consistency model</a><ul><li><a href=#our-notation aria-label="Our notation">Our notation</a></li><li><a href=#strict-consistency aria-label="Strict Consistency">Strict Consistency</a></li><li><a href=#sequential-consistency aria-label="Sequential Consistency">Sequential Consistency</a></li><li><a href=#causal-consistency aria-label="Causal Consistency">Causal Consistency</a></li><li><a href=#weak-consistency aria-label="Weak Consistency">Weak Consistency</a></li></ul></li></ul></li></ul></div></details></div><div class=post-content><h1 id=operating-systems-overview>Operating Systems Overview<a hidden class=anchor aria-hidden=true href=#operating-systems-overview>#</a></h1><hr><h3><a href=https://github.com/github/docs/files/12329707/OS-All-Notes.pdf target=_blank>Download PDF Notes➥</a></h3><iframe loading=lazy src=https://scdn.web.app/books-pdfs/1-Placements-Notes/OS-All-Notes.pdf width=100% height=600></iframe><p><strong>Operating Systems</strong> :</p><ul><li>Direct operational resources [CPU, memory, devices]</li><li>Enforces working policies [Resource usage, access]</li><li>Mitigates difficulty of complex tasks [abstract hardware details (using system calls)]</li></ul><h2 id=what-is-an-operating-system>What is an Operating System?<a hidden class=anchor aria-hidden=true href=#what-is-an-operating-system>#</a></h2><ul><li>Intermediate between Hardware and Software applications</li><li>Hides hardware complexity (Read/write file storage, send/receive socket network)</li><li>Handles resource management (CPU scheduling, Memory management)</li><li>Provide isolation and protection (allocate different parts of memory to different applications so that applications don&rsquo;t overwrite other memory locations)</li></ul><h2 id=operating-system-definition>Operating System definition:<a hidden class=anchor aria-hidden=true href=#operating-system-definition>#</a></h2><p>An <strong>Operating System</strong> is a layer of systems software that:</p><ul><li>directly has privileged access to the underlying hardware;</li><li>hides the hardware complexity;</li><li>manages hardware on behalf of one or more application according to some predifined policies.</li><li>In addition, it ensures that applications are isolated and protected from one another.</li></ul><h2 id=operating-system-examples>Operating System examples:<a hidden class=anchor aria-hidden=true href=#operating-system-examples>#</a></h2><table><thead><tr><th>Desktop</th><th>Embedded devices</th></tr></thead><tbody><tr><td>Microsoft Windows</td><td>Android OS</td></tr><tr><td>MAC OS X (BSD)</td><td>iOS</td></tr><tr><td>LINUX</td><td>Symbian</td></tr><tr><td>&mldr;</td><td>&mldr;</td></tr></tbody></table><h2 id=os-elements>OS Elements<a hidden class=anchor aria-hidden=true href=#os-elements>#</a></h2><ul><li><strong>Abstractions</strong> (corresponds to applications that OS executes)<ul><li>process, thread, file, socket, memory page</li></ul></li><li><strong>Mechanisms</strong> (on top of Abstractions)<ul><li>create, schedule, open, write, allocate</li></ul></li><li><strong>Policies</strong> (how mechanisms are used to manage underlying hardware)<ul><li>Least Recently Used (LRU) , Earliest Deadline First (EDF), etc.</li></ul></li></ul><h4 id=example->Example :<a hidden class=anchor aria-hidden=true href=#example->#</a></h4><p><em>Memory Management:</em></p><ul><li><strong>Abstractions</strong>: Memory page</li><li><strong>Mechanisms</strong>: Allocate, map to a process</li><li><strong>Policies</strong>: LRU</li></ul><h2 id=os-design-principles>OS Design Principles<a hidden class=anchor aria-hidden=true href=#os-design-principles>#</a></h2><ul><li>Seperation of mechanism and policy<ul><li>implement flexible mechanisms to support many policies</li><li>e.g. LRU, LFU, random</li></ul></li><li>Optimize for common case<ul><li>Where will the OS be used?</li><li>What will the user want to execute on that machine?</li><li>What are the workload requirements?</li></ul></li></ul><h2 id=user-kernel-protection-boundary>User/ Kernel Protection Boundary<a hidden class=anchor aria-hidden=true href=#user-kernel-protection-boundary>#</a></h2><ul><li>user-level => applications [underprivileged mode]</li><li>kernel-level => OS Kernel [privileged access, hardware access]</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/userkernelprotectionboundary.png alt=userkernelprotectionboundary></p><ul><li>User-Kernel switch is supported by hardware.<ul><li>using trap instructions</li><li>system calls like:<ul><li>open (file)</li><li>send (socket)</li><li>malloc (memory)</li></ul></li><li>signals</li></ul></li></ul><h2 id=system-call-flowcart>System call Flowcart<a hidden class=anchor aria-hidden=true href=#system-call-flowcart>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/systemcallflowchart.png alt=systemcallflowchart></p><ul><li>To make a system call, an application must:<ul><li>write arguments</li><li>save relevant data ast well defined location</li><li>make system calls using system call number</li></ul></li><li>In synchronous mode : wait until system call completes.</li></ul><h2 id=basic-os-services>Basic OS services<a hidden class=anchor aria-hidden=true href=#basic-os-services>#</a></h2><ul><li>process management</li><li>file management</li><li>device management</li><li>memory management</li><li>storage management</li><li>security</li></ul><h2 id=linux-system-calls>Linux System Calls<a hidden class=anchor aria-hidden=true href=#linux-system-calls>#</a></h2><table><thead><tr><th>Task</th><th>Commands</th></tr></thead><tbody><tr><td>Process Control</td><td>fork (); exit(); wait();</td></tr><tr><td>File Manipulation</td><td>open(); read(); write();</td></tr><tr><td>Device Manipulation</td><td>ioctl(); read(); write();</td></tr><tr><td>Information Maintenance</td><td>getpid(); alarm(); sleep();</td></tr><tr><td>Communication</td><td>pipe(); shmget(); mmap();</td></tr><tr><td>Protection</td><td>chmod(); umask(); chown();</td></tr></tbody></table><h2 id=linux-architecture>Linux Architecture<a hidden class=anchor aria-hidden=true href=#linux-architecture>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/linuxarch.png alt=linuxarchitecture></p><hr><h1 id=process-and-process-management>Process and Process Management<a hidden class=anchor aria-hidden=true href=#process-and-process-management>#</a></h1><p><strong>Process</strong>: Instance of an executing program.</p><ul><li>State of execution<ul><li>program counter, stack pointer</li></ul></li><li>Parts and temporary holding area<ul><li>data, register state, occupies state in memory</li></ul></li><li>May require special hardware<ul><li>I/O devices</li></ul></li></ul><p>Process is a state of a program when executing and loaded in memory (active state) as opposed to application (static state).</p><h2 id=what-does-a-process-look-like>What does a process look like?<a hidden class=anchor aria-hidden=true href=#what-does-a-process-look-like>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/process.png alt=Process></p><h3 id=type-of-state>Type of state<a hidden class=anchor aria-hidden=true href=#type-of-state>#</a></h3><ul><li>Text and Data<ul><li>static state when process loads first</li></ul></li><li>Heap<ul><li>dynamically created during execution</li></ul></li><li>Stack<ul><li>grows and shrinks</li><li>LIFO queue (used to store task checkpoints to resume the original process after switching from another.)</li></ul></li></ul><h2 id=how-does-the-os-know-what-a-process-is-doing>How does the OS know what a process is doing?<a hidden class=anchor aria-hidden=true href=#how-does-the-os-know-what-a-process-is-doing>#</a></h2><p>Using:</p><ul><li>Program counter</li><li>CPU registers</li><li>Stack pointer</li></ul><h2 id=process-control-block-pcb>Process Control Block (PCB)<a hidden class=anchor aria-hidden=true href=#process-control-block-pcb>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/pcb.png alt=PCB></p><ul><li>PCB created when process is created</li><li>Certain fields are updated when process state change e.g. memory mapping</li><li>or other fields that change very frequently e.g. Program Counter</li></ul><h2 id=how-is-pcb-used->How is PCB used ?<a hidden class=anchor aria-hidden=true href=#how-is-pcb-used->#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/howpcbisused.png alt=howpcbisused></p><h2 id=context-switch>Context Switch<a hidden class=anchor aria-hidden=true href=#context-switch>#</a></h2><ul><li>Mechanism used to switch from the context of one process to another in the CPU.</li></ul><ul><li>They are expensive!<ul><li>direct costs: no of cycles for load and store instructions.</li><li>indirect costs: <strong>COLD</strong> cache (read more <a href=https://stackoverflow.com/questions/22756092/what-does-it-mean-by-cold-cache-and-warm-cache-concept>here</a>)<ul><li>Therefore limit frequency how context switching is done.</li></ul></li></ul></li></ul><p>When a cache is <strong>HOT</strong>, most process data is in the cache so the process performance will be at its best.</p><p>Sometimes there are situations where we have to Context Switch (higher priority process, timesharing, etc.)</p><h2 id=process-lifecycle>Process Lifecycle<a hidden class=anchor aria-hidden=true href=#process-lifecycle>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/processlifecycle.png alt=processlifecycle></p><p>CPU is able to execute a process when the process is in Running or Ready state.</p><h2 id=process-creation>Process Creation<a hidden class=anchor aria-hidden=true href=#process-creation>#</a></h2><h4 id=mechanisms>Mechanisms:<a hidden class=anchor aria-hidden=true href=#mechanisms>#</a></h4><ul><li><p>fork :</p><ul><li>copies the parent PCB into new child PCB</li><li>child contains execution at instruction after fork</li></ul></li><li><p>exec :</p><ul><li>replace child image</li><li>load new program and start from first instruction</li></ul></li></ul><h2 id=what-is-the-role-of-cpu-scheduler>What is the role of CPU scheduler?<a hidden class=anchor aria-hidden=true href=#what-is-the-role-of-cpu-scheduler>#</a></h2><p>CPU scheduler determines which one of the currently ready processes will be dispatched to the CPU to start running, and how long it should run for.</p><p>OS must :</p><ul><li>preempt => interrupt and save current context</li><li>schedule => run scheduler to choose next process</li><li>dispatch => dispatch process 2 switch into its context</li></ul><h2 id=scheduling-design-decisions>Scheduling design decisions<a hidden class=anchor aria-hidden=true href=#scheduling-design-decisions>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/timeslice.png alt=timeslice></p><ul><li>What are the appropriate timeslice values?</li><li>Metrics to choose next process to run?</li></ul><h2 id=io>I/O<a hidden class=anchor aria-hidden=true href=#io>#</a></h2><p>A process can make way in the ready queue in a number of ways.</p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/io.png alt=io></p><h2 id=can-process-interact>Can process interact?<a hidden class=anchor aria-hidden=true href=#can-process-interact>#</a></h2><h4 id=inter-process-communication>Inter Process communication:<a hidden class=anchor aria-hidden=true href=#inter-process-communication>#</a></h4><p>IPC mechanisms:</p><ul><li>transfer data/info between address space</li><li>maintain protection and isolation</li><li>provide flexibility and performance</li></ul><p>Two types of IPC models:</p><h4 id=1-message-passing-ipc>1. <strong>Message Passing IPC</strong><a hidden class=anchor aria-hidden=true href=#1-message-passing-ipc>#</a></h4><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/messagepassing.png alt=messagepassing></p><ul><li>OS provides communication channel line shared buffer</li><li>Processes can write(send), read(receive) msg to/from channel</li></ul><p><strong>Advantages</strong>: OS manages the channel<br><strong>Disadvantages</strong>: Overheads</p><h4 id=2-shared-memory-ipc>2. <strong>Shared Memory IPC</strong><a hidden class=anchor aria-hidden=true href=#2-shared-memory-ipc>#</a></h4><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/sharedmemory.png alt=sharedmemory></p><ul><li>OS establishes a shared channel and maps it into each processes&rsquo; address space</li><li>Processes directly write(send), read(receive) msg to/from this memory</li></ul><p><strong>Advantages</strong>: OS is out of the way after establishing the shared channel<br><strong>Disadvantages</strong>: Re-implementing a lot of code that could have been done by the OS</p><p>Overall, <strong>shared memory</strong> based communication is better if mapping memory between two processes is ammortized over a large number of messages.</p><hr><h1 id=threads-and-concurrency>Threads and Concurrency<a hidden class=anchor aria-hidden=true href=#threads-and-concurrency>#</a></h1><p><strong>Thread</strong>:</p><ul><li>is an active<ul><li>entity executing unit of a process</li></ul></li><li>works simultaneously with others<ul><li>many threads execute together</li></ul></li><li>requires coordination<ul><li>sharing of I/O devices, CPUs, memory</li></ul></li></ul><h2 id=process-vs-thread>Process vs Thread<a hidden class=anchor aria-hidden=true href=#process-vs-thread>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/processvthread.png alt=processvthread></p><h2 id=why-are-threads-useful>Why are threads useful?<a hidden class=anchor aria-hidden=true href=#why-are-threads-useful>#</a></h2><ul><li>Parallelization => Speedup</li><li>Specialization => Hot cache</li><li>Efficiency => lower memory requirement & cheaper IPC</li><li>Time for context switch in threads is less, since memory is shared, hence mapping is not required between virtual and physical memory.<ul><li>Therefore multithreading can be used to hide latency.</li></ul></li><li>Benefits to both applicatioons and OS code<ul><li>Multithreaded OS kernel<ul><li>threads working on behalf of applications</li><li>OS level services like daemons and drivers</li></ul></li></ul></li></ul><h2 id=what-do-we-need-to-support-threads>What do we need to support threads?<a hidden class=anchor aria-hidden=true href=#what-do-we-need-to-support-threads>#</a></h2><ul><li>Threads data structure<ul><li>Identify threads, keep track of resource usage..</li></ul></li><li>Mechanisms to create and manage threads</li><li>Mechanisms to safely coordinate among threads running concurrently in the same address space</li></ul><h2 id=concurrency-control-and-coordination>Concurrency control and Coordination<a hidden class=anchor aria-hidden=true href=#concurrency-control-and-coordination>#</a></h2><ul><li>Mutual exclusion<ul><li>Exclusive access to only one thread at a time</li><li><strong>mutex</strong></li></ul></li><li>Waiting on other threads<ul><li>Specific condition before proceeding</li><li><strong>condition variable</strong></li></ul></li><li>Waking up other threads from wait state</li></ul><h2 id=threads-and-threads-creation>Threads and Threads creation<a hidden class=anchor aria-hidden=true href=#threads-and-threads-creation>#</a></h2><ul><li><p>Thread data structure:</p><ul><li>Thread type, Thread ID, PC, SP, registers, stack, attributes.</li></ul></li><li><p><strong>Fork</strong>(proc, args)</p><ul><li>create a thread</li><li>not UNIX fork</li></ul></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-0-1><a class=lnlinks href=#hl-0-1>1</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>t1 = fork(proc, args)   
</span></span></code></pre></td></tr></table></div></div><ul><li><strong>Join</strong>(thread)<ul><li>terminate a thread</li></ul></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-1-1><a class=lnlinks href=#hl-1-1>1</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>child_result = join(t1)   
</span></span></code></pre></td></tr></table></div></div><h3 id=example>Example:<a hidden class=anchor aria-hidden=true href=#example>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-2-1><a class=lnlinks href=#hl-2-1>1</a>
</span><span class=lnt id=hl-2-2><a class=lnlinks href=#hl-2-2>2</a>
</span><span class=lnt id=hl-2-3><a class=lnlinks href=#hl-2-3>3</a>
</span><span class=lnt id=hl-2-4><a class=lnlinks href=#hl-2-4>4</a>
</span><span class=lnt id=hl-2-5><a class=lnlinks href=#hl-2-5>5</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Thread  t1;
</span></span><span class=line><span class=cl>Shared_List list;
</span></span><span class=line><span class=cl>t1 = fork(safe_insert, 4);
</span></span><span class=line><span class=cl>safe_insert(6);
</span></span><span class=line><span class=cl>join(t1); //Optional
</span></span></code></pre></td></tr></table></div></div><p>The list can be accessed by reading shared variable.</p><h2 id=mutual-exclusion>Mutual Exclusion<a hidden class=anchor aria-hidden=true href=#mutual-exclusion>#</a></h2><ul><li>Mutex data structure:<ul><li>locked?, owner, blocked_threads</li></ul></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-3-1><a class=lnlinks href=#hl-3-1>1</a>
</span><span class=lnt id=hl-3-2><a class=lnlinks href=#hl-3-2>2</a>
</span><span class=lnt id=hl-3-3><a class=lnlinks href=#hl-3-3>3</a>
</span><span class=lnt id=hl-3-4><a class=lnlinks href=#hl-3-4>4</a>
</span><span class=lnt id=hl-3-5><a class=lnlinks href=#hl-3-5>5</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>lock(mutex){
</span></span><span class=line><span class=cl>	//Critical Section
</span></span><span class=line><span class=cl>    //Only one thread can access at a time
</span></span><span class=line><span class=cl>}
</span></span><span class=line><span class=cl>unlock(mutex)
</span></span></code></pre></td></tr></table></div></div><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/mutex.png alt=mutex></p><h2 id=producer-consumer-problem>Producer Consumer problem<a hidden class=anchor aria-hidden=true href=#producer-consumer-problem>#</a></h2><p>What if the processing you wish to perform with mutual exclusion needs to occur under certai conditions?</p><p>For e.g. The producer appends items to a list until the list is full, and the consumer has to print out all the items of the list once the list if full and then empty the list. Thus we have to execute the Consumer thread only under a certain condition (here- when the list becomes empty, print items).</p><p>Solution: Use <strong>Condition Variables</strong></p><ul><li><p>Wait(mutex, condition)</p><ul><li>mutex is automatically released and reaquired on wait</li><li>The consumer applies <em>Wait</em> until the list is full</li></ul></li><li><p>Signal(condition)</p><ul><li>Notify only one thread waiting on condition</li><li>The Producer applies <em>Signal</em> to the Consumer thread when the list is full</li></ul></li><li><p>Broadcast(condition)</p><ul><li>Notify all waiting threads</li></ul></li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/producerconsumer.png alt=producerconsumer></p><h2 id=readers--writer-problem>Readers / Writer problem<a hidden class=anchor aria-hidden=true href=#readers--writer-problem>#</a></h2><ul><li>0 or more readers can access a resource</li><li>0 or 1 writer can write the resource concurrently at the same time</li></ul><ul><li><p>One solution:</p><ul><li>lock on resource<ul><li>good for writer</li><li>too restrictive for readers</li></ul></li></ul></li><li><p>Better solution:</p></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-4-1><a class=lnlinks href=#hl-4-1>1</a>
</span><span class=lnt id=hl-4-2><a class=lnlinks href=#hl-4-2>2</a>
</span><span class=lnt id=hl-4-3><a class=lnlinks href=#hl-4-3>3</a>
</span><span class=lnt id=hl-4-4><a class=lnlinks href=#hl-4-4>4</a>
</span><span class=lnt id=hl-4-5><a class=lnlinks href=#hl-4-5>5</a>
</span><span class=lnt id=hl-4-6><a class=lnlinks href=#hl-4-6>6</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>if ((read_count == 0) &amp; (read_count == 0))
</span></span><span class=line><span class=cl>	R okay, W okay
</span></span><span class=line><span class=cl>if (read_count &gt; 0)
</span></span><span class=line><span class=cl>	R okay    
</span></span><span class=line><span class=cl>if (read_count == 1)
</span></span><span class=line><span class=cl>	R not-okay, W not-okay    
</span></span></code></pre></td></tr></table></div></div><p>State of shared resource:</p><ul><li>free : resource_counter = 0</li><li>reading : resource_counter > 0</li><li>writing : resource_counter = -1</li></ul><p>Thus essentially we can apply mutex on the new proxy &lsquo;resource_counter&rsquo; variable that represents the state of the shared resource.</p><h2 id=avoiding-common-mistakes>Avoiding common mistakes<a hidden class=anchor aria-hidden=true href=#avoiding-common-mistakes>#</a></h2><ul><li>keep track of mutex/lock variable used with a resource<ul><li>e.g. mutex_type m1; // mutex for file1</li></ul></li><li>check that you are always and correctly using lock and unlock - Compilers can be used as they generate errors/warnings to correct this type of mistake</li><li>Use a single mutex to access a single resource</li><li>check that you are signalling correct condition</li><li>check that you are not using signal when broadcast is needed<ul><li>signal : only 1 thread is will proceed, remaining threads will wait</li></ul></li><li>check thread execution order to be controlled by signals to condition variables</li></ul><h2 id=spuriousunnecessary-wake-ups>Spurious(Unnecessary) Wake ups<a hidden class=anchor aria-hidden=true href=#spuriousunnecessary-wake-ups>#</a></h2><p>When we wake up threads knowing they may not be able to proceed.</p><h2 id=deadlocks>Deadlocks<a hidden class=anchor aria-hidden=true href=#deadlocks>#</a></h2><p>Two or more competing threads are said to be in a deadlock if they are waiting on each other to complete, but none of them ever do.</p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/deadlock.png alt=deadlock></p><p>Here T1 and T2 are in deadlock.</p><h3 id=how-to-avoid-this>How to avoid this?<a hidden class=anchor aria-hidden=true href=#how-to-avoid-this>#</a></h3><ol><li>Unlock T1 before locking T2<ul><li>Fine-grained locking but T1 nad T2 may both be required</li></ul></li><li>Use one mega lock, get all locks upfront, then release at end<ul><li>For some applications this may be ok. But generally its too restrictive and limits parallelism</li></ul></li><li>Maintain lock order<ul><li>first m_T1</li><li>then m_T2<ul><li>this will prevent cycles in wait graph</li></ul></li></ul></li></ol><p>A cycle in wait graph is necessary and sufficient for deadlock to occur.<br>(thread-waiting-on-resource &mdash;edge&mdash;> thread-owning-resource)</p><ul><li><p>Deadlock prevention => Expensive<br>Pre-check for cycles and then delay process or change code</p></li><li><p>Deadlock Detection and Recovery => Rollback</p></li></ul><h2 id=kernel-vs-user-level-threads>Kernel vs User level Threads<a hidden class=anchor aria-hidden=true href=#kernel-vs-user-level-threads>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/kernelvuserthread.png alt=kernelvuserthread></p><p>Three types of models:</p><h4 id=1-one-to-one-model>1. <strong>One to One model</strong>:<a hidden class=anchor aria-hidden=true href=#1-one-to-one-model>#</a></h4><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/onetoone.png alt=onetoone></p><p><strong>Advantages</strong>:</p><ul><li>OS sees threads</li><li>Synchronization</li><li>Blocking</li></ul><p><strong>Disadvantages</strong>:</p><ul><li>Must go to OS for all operations</li><li>OS may have limits on policies, threads</li><li>Portability</li></ul><h4 id=2-many-to-one-model>2. <strong>Many to One model</strong>:<a hidden class=anchor aria-hidden=true href=#2-many-to-one-model>#</a></h4><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/manytoone.png alt=manytoone></p><p><strong>Advantages</strong>:</p><ul><li>Totally Portable</li><li>Doesn&rsquo;t depend on OS limits and policies</li></ul><p><strong>Disadvantages</strong>:</p><ul><li>OS may block entire process if one user-level thread blocks on I/O</li></ul><h4 id=3-many-to-many-model>3. <strong>Many to Many model</strong>:<a hidden class=anchor aria-hidden=true href=#3-many-to-many-model>#</a></h4><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/manytomany.png alt=manytomany></p><p><strong>Advantages</strong>:</p><ul><li>Best of both worlds</li><li>Can have bound or unbound threads</li></ul><p><strong>Disadvantages</strong>:</p><ul><li>Requires coordination between user and kernel level thread managers</li></ul><h2 id=multithreading-patterns>Multithreading patterns<a hidden class=anchor aria-hidden=true href=#multithreading-patterns>#</a></h2><p><strong>1. Boss-Workers pattern</strong></p><ul><li>Boss- assigns work</li><li>Workers- perform entire task</li></ul><p>Throughput of system is limited by boss thread. Hence boss thread must be kept efficient.</p><p>Throughput = 1/boss-time-orders</p><p>Boss assigns works by:</p><ol><li>Directly signalling specific works<ul><li><strong>+</strong> workers don&rsquo;t need to sync</li><li><strong>-</strong> boss must keep track of everyone</li></ul></li><li>Placing work in queue<ul><li><strong>+</strong> boss doesn&rsquo;t neeed to know details about workers</li><li><strong>-</strong> queue synchronization</li></ul></li></ol><p>How many workers?</p><ul><li>on demand</li><li>pool of workers</li><li>static vs dynamic (i.e dynamically increasing size according to work)</li></ul><p><strong>Advantages</strong>:</p><ul><li>Simplicity</li></ul><p><strong>Disadvantages</strong>:</p><ul><li>Thread pool management</li><li>Locality</li></ul><p><strong>1B. Boss-Workers pattern variant</strong></p><ul><li>Here workers are specialized for certain tasks opposite to the previous equally created workers</li></ul><p><strong>Advantages</strong>:</p><ul><li>Better locality</li><li>Quality of Service management</li></ul><p><strong>Disadvantages</strong>:</p><ul><li>Load balancing</li></ul><p><strong>2. Pipeline pattern</strong></p><ul><li>Threads assigned one subtask in the system</li><li>Entire task = Pipeline of threads</li><li>Multiple tasks concurrently run in the system, in different pipeline stages</li><li>Throughput depends on weakest link</li><li>Shared buffer based communication between stages</li></ul><p><strong>3. Layered pattern</strong></p><ul><li>Layers of threads are assigned group of related subtasks</li><li>End to end task must pass up and down through all layers</li></ul><p><strong>Advantages</strong>:</p><ul><li>Specialization</li><li>Less fine-grained than pipeline</li></ul><p><strong>Disadvantages</strong>:</p><ul><li>Not suitable for all applications</li><li>Synchronization</li></ul><h3 id=example-1>Example:<a hidden class=anchor aria-hidden=true href=#example-1>#</a></h3><p><strong>Q)</strong> For 6 step toy order application we have 2 solutions:</p><ol><li>Boss-workers solution</li><li>Pipeline solution</li></ol><p>Both have 6 threads. In the boss-workers solution, a worker produces a toy order in 120 ms. In the pipeline solution, each of 6 stages take 20 ms.</p><p>How long will it take for these solutions to complete 10 toy orders and 11 toy orders?</p><p><strong>A)</strong> 6 threads means for Boss-workers, 1 thread is for boss, 5 for workers. In pipeline 6 threads are equally used.</p><p>For 10 toy orders:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-5-1><a class=lnlinks href=#hl-5-1>1</a>
</span><span class=lnt id=hl-5-2><a class=lnlinks href=#hl-5-2>2</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Boss-workers(10) = 120 + 120 = 240 ms
</span></span><span class=line><span class=cl>Pipeline(10) = 120 + (9*20) = 300 ms
</span></span></code></pre></td></tr></table></div></div><p>Here Boss-workers is better than Pipeline.</p><p>For 11 toy orders:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-6-1><a class=lnlinks href=#hl-6-1>1</a>
</span><span class=lnt id=hl-6-2><a class=lnlinks href=#hl-6-2>2</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Boss-workers(11) = 120 + 120 + 120 = 360 ms
</span></span><span class=line><span class=cl>Pipeline(11) = 120 + (10*20) = 320 ms
</span></span></code></pre></td></tr></table></div></div><p>Here Pipeline is better than Boss-workers.</p><p>This proves that choosing a better pattern depends on the number of threads and the work required to be done.</p><h2 id=pthreads>PThreads<a hidden class=anchor aria-hidden=true href=#pthreads>#</a></h2><p>PThreads == POSIX Threads</p><p>POSIX = Portable OS interface</p><h3 id=compiling-pthreads>Compiling PThreads<a hidden class=anchor aria-hidden=true href=#compiling-pthreads>#</a></h3><ol><li>#include&lt;pthread.h> in main file</li><li>Compile source with -lpthread or -pthread</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-7-1><a class=lnlinks href=#hl-7-1>1</a>
</span><span class=lnt id=hl-7-2><a class=lnlinks href=#hl-7-2>2</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>gcc -o main main.c -lpthread
</span></span><span class=line><span class=cl>gcc -o main main.c -pthread
</span></span></code></pre></td></tr></table></div></div><ol start=3><li>Check return values of common examples</li></ol><h3 id=pthread-mutexes>PThread mutexes<a hidden class=anchor aria-hidden=true href=#pthread-mutexes>#</a></h3><ul><li>to solve mutual exclusion problems among concurrent threads</li></ul><h3 id=safety-tips>Safety tips<a hidden class=anchor aria-hidden=true href=#safety-tips>#</a></h3><ul><li>Shared data should always be accessed through single mutex</li><li>Mutex scope must be visible to all</li><li>Globally order locks<ul><li>for all threads, lock mutexes in order</li></ul></li><li>Always unlock a mutex (correctly)</li></ul><h2 id=thread-design-considerations>Thread Design Considerations<a hidden class=anchor aria-hidden=true href=#thread-design-considerations>#</a></h2><h3 id=kernel-vs-user-level-threads-1>Kernel vs User Level Threads<a hidden class=anchor aria-hidden=true href=#kernel-vs-user-level-threads-1>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/userlevelvkernellevel.png alt=userlevelvkernellevel></p><h3 id=thread-related-data-structures>Thread related data structures<a hidden class=anchor aria-hidden=true href=#thread-related-data-structures>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/threadds.png alt=threadds></p><h3 id=hard-vs-light-process-states>Hard vs Light Process states<a hidden class=anchor aria-hidden=true href=#hard-vs-light-process-states>#</a></h3><p>PCB is divided into multiple data structures classified as follows:</p><ul><li>Light Process states<ul><li>Signal mask</li><li>System call args</li></ul></li><li>Heavy Process states<ul><li>virtual address mapping</li></ul></li></ul><h4 id=rationale-for-multiple-data-structures>Rationale for Multiple Data Structures:<a hidden class=anchor aria-hidden=true href=#rationale-for-multiple-data-structures>#</a></h4><table><thead><tr><th>Single PCB</th><th>Multiple DS</th></tr></thead><tbody><tr><td>Large continuos DS</td><td>Smaller DS</td></tr><tr><td>Private for each entity</td><td>Easier to share</td></tr><tr><td>Saved and restored on each context switch</td><td>Save and Restore only what needs to change on context switch</td></tr><tr><td>Update for any changes</td><td>User lever library need to only update portion of the state</td></tr></tbody></table><ul><li>Thus the following disadvantages for single PCB become advantages for Multiple DS :<ul><li>Scalability</li><li>Overheads</li><li>Performance</li><li>Flexibility</li></ul></li></ul><h2 id=comparison-of-interrupts-and-signals>Comparison of Interrupts and Signals<a hidden class=anchor aria-hidden=true href=#comparison-of-interrupts-and-signals>#</a></h2><ul><li>Handled in specific ways
- interrupt and signal handlers<ul><li>Can be ignored<ul><li>interrupt and signal mask</li></ul></li><li>Expected or unexpected<ul><li>appear synchronously or asynchronously</li></ul></li></ul></li></ul><ul><li>Difference:</li></ul><table><thead><tr><th>Interrupts</th><th>Signals</th></tr></thead><tbody><tr><td>Events generated externally by components other than CPU (I/O devices, timers, other CPUs)</td><td>Events triggered by CPU and software running on it</td></tr><tr><td>Determined based on physical platform</td><td>Determined based on OS</td></tr><tr><td>Appear asynchronously</td><td>Appear synchronously or asynchronously</td></tr></tbody></table><ul><li>Similarities:<ul><li>Have a unique ID depending on h/w or OS</li><li>Can be masked and disabled/suspended via corresponding mask<ul><li>per-CPU interrupt mask, preprocess signal mask</li></ul></li><li>if enabled, trigger corresponding to handler<ul><li>interrupt handler set for entire system by OS</li><li>signal handler set on per process basis by process</li></ul></li></ul></li></ul><blockquote><p>An interrupt is like a snowstorm alarm<br>A signal is like a low battery warning</p></blockquote><h3 id=interrupts>Interrupts<a hidden class=anchor aria-hidden=true href=#interrupts>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/interrupts.png alt=interrupts></p><h3 id=signals>Signals<a hidden class=anchor aria-hidden=true href=#signals>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/signals.png alt=signals></p><h4 id=handlers--actions>Handlers / Actions<a hidden class=anchor aria-hidden=true href=#handlers--actions>#</a></h4><ul><li>Default actions<ul><li>Terminate, ignore</li><li>Terminate and core dump</li><li>Stop or continue</li></ul></li><li>Process Installs Handler<ul><li>signal(), sigaction()</li><li>for most signals, some cannot be &ldquo;caught&rdquo;</li></ul></li><li><strong>Synchronous</strong><ul><li>SIGSEGV (access to protected memory)</li><li>SIGFPE (divided by zero)</li><li>SIGKILL (kill, id)<ul><li>can be directed to a specific thread</li></ul></li></ul></li><li><strong>Asynchronous</strong>*<ul><li>SIGKILL (kill)</li><li>SIGALARM</li></ul></li></ul><h3 id=why-disable-interrupts-or-signals>Why disable Interrupts or Signals<a hidden class=anchor aria-hidden=true href=#why-disable-interrupts-or-signals>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/disableis.png alt=disableis></p><p>Here PC: First instruction in handler<br>SP : thread stack</p><p>To prevent deadlock,</p><ol><li>Keep handler code simple<ul><li>avoid mutex</li><li><strong>-</strong> too restrictive</li></ul></li><li>Control interruptions by handler code<ul><li>Use interrupt/signal masks</li><li>0011100110.. (0: disabled, 1: enabled)</li></ul></li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-8-1><a class=lnlinks href=#hl-8-1> 1</a>
</span><span class=lnt id=hl-8-2><a class=lnlinks href=#hl-8-2> 2</a>
</span><span class=lnt id=hl-8-3><a class=lnlinks href=#hl-8-3> 3</a>
</span><span class=lnt id=hl-8-4><a class=lnlinks href=#hl-8-4> 4</a>
</span><span class=lnt id=hl-8-5><a class=lnlinks href=#hl-8-5> 5</a>
</span><span class=lnt id=hl-8-6><a class=lnlinks href=#hl-8-6> 6</a>
</span><span class=lnt id=hl-8-7><a class=lnlinks href=#hl-8-7> 7</a>
</span><span class=lnt id=hl-8-8><a class=lnlinks href=#hl-8-8> 8</a>
</span><span class=lnt id=hl-8-9><a class=lnlinks href=#hl-8-9> 9</a>
</span><span class=lnt id=hl-8-10><a class=lnlinks href=#hl-8-10>10</a>
</span><span class=lnt id=hl-8-11><a class=lnlinks href=#hl-8-11>11</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>clear_field_in_mask(mask)
</span></span><span class=line><span class=cl>lock(mutex)
</span></span><span class=line><span class=cl>{
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#disabled =&gt; remaining pending
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>}
</span></span><span class=line><span class=cl>unlock(mutex)
</span></span><span class=line><span class=cl>reset_field_in_mask(mask)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#enabled =&gt; execute handler code
</span></span></code></pre></td></tr></table></div></div><ul><li><p>Interrupt masks are per CPU</p><ul><li>if mask disables interrupt, hardware interrupt rounting mechanism will not deliver interrupt</li></ul></li><li><p>Signal are per execution context (User-level thread on top of Kernel-level thread)</p><ul><li>if mask disables signal, kernel sees mask and will not interrupt corresponding thread</li></ul></li></ul><h3 id=types-of-signals>Types of Signals<a hidden class=anchor aria-hidden=true href=#types-of-signals>#</a></h3><ol><li>One-shot Signals<ul><li>&ldquo;n signals pending == 1 signal pending&rdquo; : atleast once</li><li>must be explicitly re-enabled</li></ul></li><li>Realtime Signals<ul><li>&ldquo;if n signals raised, then handler is called n times&rdquo;</li></ul></li></ol><h3 id=handling-interrupts-as-threads>Handling interrupts as threads<a hidden class=anchor aria-hidden=true href=#handling-interrupts-as-threads>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/interruptsasthreads.png alt=interruptsasthreads></p><p>but dynamic thread creation is expensive!</p><ul><li>Dynamic decision<ul><li>if handler doesn&rsquo;t lock<ul><li>execute on interrupted threads stack</li></ul></li><li>if handler can block<ul><li>turn into real thread</li></ul></li></ul></li><li>Optimization<ul><li>pre-create and pre-initialize thread structure for interrupt routines</li></ul></li></ul><h3 id=threads-and-signal-handling>Threads and Signal Handling<a hidden class=anchor aria-hidden=true href=#threads-and-signal-handling>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/tshandling.png alt=tshandling></p><p><strong>Case 1 :</strong></p><ul><li>User-Level-Thread mask = 1</li><li>Kernel-Level-Thread mask = 1</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/case1.png alt=case1></p><p><strong>Case 2 :</strong></p><ul><li>User-Level-Thread mask = 0</li><li>Kernel-Level-Thread mask = 1</li><li>another User-Level-Thread mask = 1</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/case2.png alt=case2></p><p><strong>Case 3 :</strong></p><ul><li>User-Level-Thread mask = 0</li><li>Kernel-Level-Thread mask = 1</li><li>another User-Level-Thread mask = 1</li><li>another Kernel-Level-Thread mask = 1</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/case3.png alt=case3></p><p><strong>Case 4 :</strong></p><ul><li>User-Level-Thread mask = 0</li><li>Kernel-Level-Thread mask = 1</li><li>all User-Level-Thread mask = 0</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/case4.png alt=case4></p><p><strong>Optimize common case</strong></p><ul><li>signals less frequennt than signal mask updates</li><li>system calls avoided<ul><li>cheaper to update user-level mask</li></ul></li><li>signal handling more expensive</li></ul><h2 id=multi-processing-vs-multi-threading>Multi-processing vs Multi-threading<a hidden class=anchor aria-hidden=true href=#multi-processing-vs-multi-threading>#</a></h2><p>How to best provide concurrency?</p><h3 id=multi-processing-mp>Multi-Processing (MP)<a hidden class=anchor aria-hidden=true href=#multi-processing-mp>#</a></h3><p><strong>Advantages</strong><br></p><ul><li>Simple programming</li></ul><p><strong>Disadvantages</strong><br></p><ul><li>High memory usage</li><li>Costs context switch</li><li>costly to maintain shared state (tricky port setup)</li></ul><h3 id=multi-threading-mp>Multi-Threading (MP)<a hidden class=anchor aria-hidden=true href=#multi-threading-mp>#</a></h3><p><strong>Advantages</strong><br></p><ul><li>Shared address space</li><li>Shared state (no sys calls to other threads)</li><li>Cheap context switch</li></ul><p><strong>Disadvantages</strong><br></p><ul><li>Complex implementation</li><li>Requires synchronization</li><li>Requires underlying support for threads</li></ul><h2 id=event-driven-model>Event Driven model<a hidden class=anchor aria-hidden=true href=#event-driven-model>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/eventdrivenmodel.png alt=eventdrivenmodel></p><p>Features:</p><ul><li>Single address space</li><li>Single process</li><li>Single thread of control</li></ul><p>Dispatcher : acts as a state machine and accepts any external events</p><p>When call handler => jump to code</p><p>The handler:</p><ul><li>Runs to completion</li><li>if they need to block<ul><li>initiate blocking operation and pass control to dispatch loop</li></ul></li></ul><h3 id=concurrent-execution-in-event-driven-models>Concurrent execution in Event-driven models<a hidden class=anchor aria-hidden=true href=#concurrent-execution-in-event-driven-models>#</a></h3><ul><li>MP & MT : 1 request per execution context (process/thread)</li><li>Event Driven : Many requests interleaved in an execution context</li><li>Single thread switches among processing of different requests</li><li>Process requests until wait is necessary<ul><li>then switch to another request</li></ul></li></ul><p><strong>Advantages</strong><br></p><ul><li>Single address space</li><li>Single flow of control</li><li>Smaller memory requirement<ul><li>Event Driven model requires less memory than Boss-workers/Pipeline model, where the extra memory is required for helper thread for concurrent blocking I/O not for all concurrent requests.</li></ul></li><li>No context switches</li><li>No synchronization</li></ul><p><strong>Disadvantages</strong><br></p><ul><li>A blocking request/handler will block entire process</li></ul><h3 id=asynchronous-io-operations>Asynchronous I/O operations<a hidden class=anchor aria-hidden=true href=#asynchronous-io-operations>#</a></h3><p>Asynchronous I/O operations fit well with Event-driven models</p><p>Since asynchronous calls are not easily avalible, helpers can be used to implement the async call functionality:</p><ul><li>designated for blocking I/O operations only</li><li>pipe/socket based communication with event dispatcher<ul><li>select()/ poll() still okay</li></ul></li><li>helper blocks, but main event loop (& process) will not</li></ul><h3 id=asymmetric-multi-process-event-driven-model-amped--amted>Asymmetric Multi-Process Event Driven model (AMPED & AMTED)<a hidden class=anchor aria-hidden=true href=#asymmetric-multi-process-event-driven-model-amped--amted>#</a></h3><p><strong>Advantages</strong><br></p><ul><li>Resolve portability limitations of basic event driven model</li><li>Smaller footprint than regular worker thread</li></ul><p><strong>Disadvantages</strong><br></p><ul><li>Applicability to certain classes of applications</li><li>Event routing on multi CPU systems</li></ul><p>Eg <a href=https://en.wikipedia.org/wiki/Apache_HTTP_Server>Apache Web Server</a></p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/apachewebserver.png alt=apachewebserver.png></p><ul><li>Core : basic server skeleton</li><li>Modules : per functionality</li><li>Flow of Control : Similar to Event Driven model</li><li>But its an combination of MP + MT,<ul><li>each process = boss/worker with dynamic thread pool</li><li>number of processes can also be dynamically adjusted</li></ul></li></ul><hr><h1 id=scheduling>Scheduling<a hidden class=anchor aria-hidden=true href=#scheduling>#</a></h1><p>Operating System perform scheduling in the following simple ways:</p><ul><li>Dispatch orders immediately<ul><li>scheduling is simple FIFO (First-Come-First-Serve)</li></ul></li><li>Dispatch simple orders first<ul><li>maximize number of orders processed over time</li><li>maximize throughput (SJF)</li></ul></li><li>Dispatch complex orders first<ul><li>maximize utilization of CPU, devices, memory</li></ul></li></ul><h2 id=cpu-scheduler>CPU Scheduler<a hidden class=anchor aria-hidden=true href=#cpu-scheduler>#</a></h2><ul><li>Decides how and when process (and their threads) access shared CPUs</li><li>Schedules tasks running at user level processes/threads as well as kernel level threads</li><li>Chooses one of the ready tasks to run on CPU</li><li>Runs when<ul><li>CPU becomes idle</li><li>new task becomes ready</li><li>timeslice expired timeout</li></ul></li></ul><p>Context switch, enter user mode, set PC and go! &lt;= Thread is dispatched on CPU.</p><ul><li>Which task should be selected?<ul><li>Scheduling policy/algorithm</li></ul></li><li>How is this done?<ul><li>Depends on runqueue data structure</li></ul></li></ul><h3 id=run-to-completion-scheduling>&ldquo;Run-to-completion&rdquo; Scheduling<a hidden class=anchor aria-hidden=true href=#run-to-completion-scheduling>#</a></h3><ul><li>Initial assumptions<ul><li>group of tasks/jobs</li><li>known execution time</li><li>no preemption</li><li>single CPU</li></ul></li><li>Metrics<ul><li>throughput</li><li>average job completion time</li><li>average job wait time</li><li>CPU utilization</li></ul></li></ul><h2 id=scheduling-algorithms>Scheduling algorithms:<a hidden class=anchor aria-hidden=true href=#scheduling-algorithms>#</a></h2><h3 id=1-first-come-first-serve-fcfs>1. First Come First Serve (FCFS)<a hidden class=anchor aria-hidden=true href=#1-first-come-first-serve-fcfs>#</a></h3><ul><li>Schedules tasks in order of arrival</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-9-1><a class=lnlinks href=#hl-9-1>1</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>runqueue = queue(FIFO)
</span></span></code></pre></td></tr></table></div></div><p>If T1, T2, T3 arrive in the given order and T1 has execution time 1s, T2 10s and T3 1s then :</p><ul><li>Throughput = 3/(1+10+1) = 3/12 = 0.25s</li><li>Average completion time = (1 + 11 + 12)/3 = 8s</li><li>Average wait time = (1+1+11)/3 = 4s</li><li>Starvation NOT possible</li></ul><h3 id=2-shortest-job-first-sjf>2. Shortest Job First (SJF)<a hidden class=anchor aria-hidden=true href=#2-shortest-job-first-sjf>#</a></h3><ul><li>Schedules tasks in order of execution time</li><li>Therefore for the above example, T1(1s) > T3(1s) > T2(10s)</li><li>Starvation possible</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-10-1><a class=lnlinks href=#hl-10-1>1</a>
</span><span class=lnt id=hl-10-2><a class=lnlinks href=#hl-10-2>2</a>
</span><span class=lnt id=hl-10-3><a class=lnlinks href=#hl-10-3>3</a>
</span><span class=lnt id=hl-10-4><a class=lnlinks href=#hl-10-4>4</a>
</span><span class=lnt id=hl-10-5><a class=lnlinks href=#hl-10-5>5</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>runqueue = ordered(queue)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>//or
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>runqueue = tree()
</span></span></code></pre></td></tr></table></div></div><p>For SJF,</p><ul><li>Throughput = 3/(1+10+1) = 3/12 = 0.25s</li><li>Average completion time = (1 + 2 + 12)/3 = 5s</li><li>Average wait time = (0+1+2)/3 = 1s</li></ul><h3 id=preemptive-scheduling>Preemptive Scheduling<a hidden class=anchor aria-hidden=true href=#preemptive-scheduling>#</a></h3><ul><li>SJF + Preemption</li><li>Starvation is possible</li></ul><p>T2 arrives first.</p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/preemptive.png alt=preemptive></p><h3 id=priority-scheduling>Priority Scheduling<a hidden class=anchor aria-hidden=true href=#priority-scheduling>#</a></h3><ul><li>Tasks have different priority levels</li><li>Run highest priority task next (preemption)</li><li>Starvation is possible</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/priority.png alt=priority></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-11-1><a class=lnlinks href=#hl-11-1>1</a>
</span><span class=lnt id=hl-11-2><a class=lnlinks href=#hl-11-2>2</a>
</span><span class=lnt id=hl-11-3><a class=lnlinks href=#hl-11-3>3</a>
</span><span class=lnt id=hl-11-4><a class=lnlinks href=#hl-11-4>4</a>
</span><span class=lnt id=hl-11-5><a class=lnlinks href=#hl-11-5>5</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>runqueue = per priority_queue()
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>//or 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>runqueue = tree() ordered on priority
</span></span></code></pre></td></tr></table></div></div><ul><li>low priority task stuck in runqueue => starvation</li><li>&ldquo;priority aging&rdquo;<ul><li>priority = f(actual priority, time spent in runqueue)</li><li>eventually tasks will run</li><li>prevents starvation</li></ul></li></ul><h3 id=3-round-robin-scheduling>3. Round-Robin Scheduling<a hidden class=anchor aria-hidden=true href=#3-round-robin-scheduling>#</a></h3><ul><li>Pick up the first task from queue (like FCFS)</li><li>Task may yield to wait on I/O (unlike FCFCS)</li><li>Starvation is NOT possible</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/rr1.png alt=rr1></p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/rr2.png alt=rr2></p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/rr3.png alt=rr3></p><h3 id=4-shortest-remaining-time-first-srtf>4. Shortest Remaining Time First (SRTF)<a hidden class=anchor aria-hidden=true href=#4-shortest-remaining-time-first-srtf>#</a></h3><ul><li>Chooses the process with the shortest CPU burst remaining and executes that one. If processes come in during execution that have less remaining time, the current one is preempted and the new one executed. Therefore, it can lead to starvation.</li></ul><h4 id=timeslicing>Timeslicing<a hidden class=anchor aria-hidden=true href=#timeslicing>#</a></h4><ul><li>Timeslice = max amount of uninterrupted time given to a task</li><li>task may run less than timeslice<ul><li>has to wait on I/O sync<ul><li>will be placed on queue</li></ul></li><li>higher priority task becomes runnable</li></ul></li><li>using timeslice tasks are interleaved<ul><li>timesharing the CPU</li><li>CPU bound tasks => preemption after timeslice</li></ul></li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/rr4.png alt=rr4></p><p><strong>Advantages</strong><br></p><ul><li>Short tasks finish sooner</li><li>More responsive</li><li>Lengthy I/O operations initiated sooner<ul><li>best to keep timeslice > context-switch-time</li></ul></li></ul><p><strong>Disdvantages</strong><br></p><ul><li>Overheads</li></ul><h4 id=how-long-should-a-timeslice-be-be>How long should a timeslice be be?<a hidden class=anchor aria-hidden=true href=#how-long-should-a-timeslice-be-be>#</a></h4><ul><li>should balance benefits and overheads</li></ul><h3 id=for-cpu-bound-tasks>For CPU bound tasks:<a hidden class=anchor aria-hidden=true href=#for-cpu-bound-tasks>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/cputs.png alt=cputs></p><ul><li>Hence, for CPU bound tasks, larger timeslice values are better</li></ul><h3 id=for-io-bound-tasks>For I/O bound tasks:<a hidden class=anchor aria-hidden=true href=#for-io-bound-tasks>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/iots.png alt=iots></p><ul><li>Hence, for I/O bound tasks, smaller timeslice values are better<ul><li>Keeps CPU and I/P devices busy, I/O bound tasks run quickly, makes I/O requests responds to a user.</li></ul></li></ul><h3 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h3><ul><li><p>CPU bound tasks prefer longer timeslices</p><ul><li>limits context switching overheads</li><li>keeps CPU utilization and throughput</li></ul></li><li><p>I/O bound tasks prefer smaller timeslices</p><ul><li>However, if all the tasks in contention are I/O bound, it may not make such a difference</li><li>If a portion of them are I/O smaller timeslices keeps CPU and device utilization high</li><li>Provides better user-perceived performance</li></ul></li></ul><hr><h1 id=memory-management>Memory Management<a hidden class=anchor aria-hidden=true href=#memory-management>#</a></h1><p>Operating systems:</p><ul><li>uses intelligently size containers<ul><li>memory pages of segments</li></ul></li><li>Not all parts are needed at once<ul><li>tasks operate on subset of memory</li></ul></li><li>Optimized for performance<ul><li>reduce time to access state in memory<ul><li>leads to better performance!</li></ul></li></ul></li></ul><h2 id=memory-management-goals>Memory Management Goals<a hidden class=anchor aria-hidden=true href=#memory-management-goals>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/mmgoals.png alt=mmgoals.png></p><h4 id=virtual-vs-physical-memory>Virtual vs Physical memory<a hidden class=anchor aria-hidden=true href=#virtual-vs-physical-memory>#</a></h4><ul><li>Allocate<ul><li>allocation, replacement</li></ul></li><li>Arbitrate<ul><li>address translation and validation</li></ul></li></ul><h4 id=page-based-memory-management>Page-based Memory Management<a hidden class=anchor aria-hidden=true href=#page-based-memory-management>#</a></h4><ul><li>Allocate => pages => page frames</li><li>Arbitrate => page tables</li></ul><h4 id=segment-based-memory-management>Segment-based Memory Management<a hidden class=anchor aria-hidden=true href=#segment-based-memory-management>#</a></h4><ul><li>Allocate => segments</li><li>Arbitrate => segment registers</li></ul><h2 id=hardware-support>Hardware Support<a hidden class=anchor aria-hidden=true href=#hardware-support>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/hardwaresupport.png alt=hardwaresupport.png></p><h3 id=memory-management-unit-mmu>Memory Management Unit (MMU)<a hidden class=anchor aria-hidden=true href=#memory-management-unit-mmu>#</a></h3><ul><li>translate virtual to physical address</li><li>reports faults (illegal access, permission, not present in memory)</li></ul><h3 id=registers>Registers<a hidden class=anchor aria-hidden=true href=#registers>#</a></h3><ul><li>pointers to page tables</li><li>base and limit size, number of segments</li></ul><h3 id=cache>Cache<a hidden class=anchor aria-hidden=true href=#cache>#</a></h3><ul><li>Translation lookaside buffer</li><li>Valid VA-PA translations using TLB</li></ul><h3 id=translation>Translation<a hidden class=anchor aria-hidden=true href=#translation>#</a></h3><ul><li>Actual PA generation done in hardware</li></ul><h2 id=page-tables>Page Tables<a hidden class=anchor aria-hidden=true href=#page-tables>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/pagetables.png alt=pagetables.png></p><ul><li>OS creates page table per process</li><li>On context switch, switch to valid page table</li><li>Updates register that points to correct page table.
E.g CR3 on x86 architecture</li></ul><h2 id=page-table-entry-pte>Page Table Entry (PTE)<a hidden class=anchor aria-hidden=true href=#page-table-entry-pte>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/pfn.png alt=pfn.png></p><h4 id=flags>Flags<a hidden class=anchor aria-hidden=true href=#flags>#</a></h4><ul><li>Present (valid/invalid)</li><li>Dirty (written to)</li><li>Accessed (for read or write)</li><li>Protection bits => RWX</li></ul><h2 id=page-table-entry-on-x86>Page Table Entry on x86<a hidden class=anchor aria-hidden=true href=#page-table-entry-on-x86>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/pfnx86.png alt=pfnx86.png></p><h4 id=flags-1>Flags<a hidden class=anchor aria-hidden=true href=#flags-1>#</a></h4><ul><li>Present</li><li>Dirty</li><li>Accessed</li><li>R/W permission bit 0: R only, 1: R/W</li><li>U/S permission bit 0: usermode, 1: superviser mode only</li><li>others: caching related info (write through, caching disabled)</li><li>unused: for future use</li></ul><h2 id=page-faults>Page faults<a hidden class=anchor aria-hidden=true href=#page-faults>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/pagefaults.png alt=pagefaults.png></p><h2 id=page-table-size>Page Table Size<a hidden class=anchor aria-hidden=true href=#page-table-size>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/pts.png alt=pts.png></p><ul><li>32 bit architecture<ul><li>Page Table Entry (PTE) = 4 Bytes, including PFN + flags</li><li>Virtual Page Number (VPN) = 2^32/page_size</li><li>Page size = 4KB (&mldr;8KB, 2MB, 4MB, 1GB)</li></ul></li></ul><p>Therefore Page Table Size = (2^32 * 2^12)*4B = 4MB (per process)</p><ul><li>for 64 bit architecture<ul><li>Page Table Entry (PTE) = 8 Bytes</li><li>Page size = 4KB</li></ul></li></ul><p>Page Table Size = (2^64 * 2^12)*8B = 32PB (per process!)</p><ul><li>processes don&rsquo;t use entire address space</li><li>even on 32 bit architecture, it will not always use all 4GB</li></ul><p>But Page Table assumes an entry per VPN regardless, of whether corresponding virtual memory is needed or not.</p><h2 id=hierarchical-page-tables>Hierarchical Page Tables<a hidden class=anchor aria-hidden=true href=#hierarchical-page-tables>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/hierarchicalpt.png alt=hierarchicalpt.png></p><p>On malloc, a new internal page table may be allocated.</p><h4 id=address-split>Address split:<a hidden class=anchor aria-hidden=true href=#address-split>#</a></h4><table><tr><th colspan=2>Page Number</th><th>offset</th></tr><tr><td>P1</td><td>P2</td><td>d</td></tr><tr><td>12</td><td>10</td><td>10</td></tr></table><ul><li>inner table addresses => 2^10 * page_size = 2^10*2^10 = 1MB</li><li>don&rsquo;t need an inner table for each 1MB virtual memory gap</li></ul><p>Additional Layers</p><ul><li>page table directory pointer (3rd level)</li><li>page table directory map (4th level)</li></ul><ul><li>Important on 64 bit architectures</li><li>larger and more sparse => larger gaps would save more internal page table components</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/hierarchicalpt2.png alt=hierarchicalpt2.png></p><h3 id=tradeoffs-of-multilevel-page-tables>Tradeoffs of Multilevel Page Tables<a hidden class=anchor aria-hidden=true href=#tradeoffs-of-multilevel-page-tables>#</a></h3><p><strong>Advantages</strong><br></p><ul><li>Smaller internal page tables/directories</li><li>Granularity of coverage<ul><li>Potentially reduced page table size</li></ul></li></ul><p><strong>Disadvantages</strong><br></p><ul><li>More memory accesses required for translation</li><li>increased translation latency</li></ul><h2 id=overheads-of-address-translation>Overheads of Address Translation<a hidden class=anchor aria-hidden=true href=#overheads-of-address-translation>#</a></h2><p>For each memory reference :</p><table><thead><tr><th>Single level page table</th><th>Four level page table</th></tr></thead><tbody><tr><td>x1 access to PTE</td><td>x4 accesses to PTE</td></tr><tr><td>x1 access to mem</td><td>x1 access to mem</td></tr></tbody></table><p>which results in slowdown.</p><h2 id=page-table-cache>Page Table Cache<a hidden class=anchor aria-hidden=true href=#page-table-cache>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/ptcache.png alt=ptcache.png></p><h4 id=translation-lookaside-buffer>Translation Lookaside Buffer<a hidden class=anchor aria-hidden=true href=#translation-lookaside-buffer>#</a></h4><ul><li>MMU level address translation cache</li><li>On TLB miss => page table access from memory</li><li>has protection/validity bits</li><li>small number of cached address => high TLB hit rate<ul><li>temporal and spatial locality</li></ul></li></ul><ul><li>Example<ul><li>x86 Core i7<ul><li>per core : 64-entry data TLB<br>128-entry instruction TLB</li><li>512-entry shared second-level TLB</li></ul></li></ul></li></ul><h3 id=inverted-page-tables>Inverted Page Tables<a hidden class=anchor aria-hidden=true href=#inverted-page-tables>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/invertedpt.png alt=invertedpt.png></p><h3 id=hashing-page-tables>Hashing Page Tables<a hidden class=anchor aria-hidden=true href=#hashing-page-tables>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/hashingpt.png alt=hashingpt.png></p><h2 id=segmentation>Segmentation<a hidden class=anchor aria-hidden=true href=#segmentation>#</a></h2><p>Segmentation is the process of mapping virtual to physical memory using segments.</p><ul><li>Segments: arbitrary granularity (size)<ul><li>e.g. code, heap, data, stack..</li><li>address = segment - selector + offset</li></ul></li><li>Segment<ul><li>contiguous physical memory</li><li>segment size = segment base + limit registers</li></ul></li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/segmentation.png alt=segmentation.png></p><h4 id=segmentation--paging>Segmentation + Paging<a hidden class=anchor aria-hidden=true href=#segmentation--paging>#</a></h4><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/segmentationpaging.png alt=segmentationpaging.png></p><h2 id=page-size>Page Size<a hidden class=anchor aria-hidden=true href=#page-size>#</a></h2><ul><li>10 bit offset => 1 KB page size [2^10]</li><li>12 bit offset => 4 KB page size [2^12]</li></ul><p>In real world examples,</p><ul><li>Linux/x86 : 4 KB, 2MB, 1GB</li><li>Solaris/Sparse: 8kB, 4MB, 2GB</li></ul><p>||Large|Huge|
|&mdash;-|&mdash;&ndash;|
|page size|2 MB|1 GB|
|offset bits|21 bits|30 bits|
|reduction factor on page table size|x512|x1024|</p><p><strong>Advantages</strong><br></p><ul><li>larger pages<ul><li>fewer page table entries, smaller page tables, more TLB hits</li></ul></li></ul><p><strong>Disadvantages</strong><br></p><ul><li>internal fragmentation => wastes memory</li></ul><h2 id=memory-allocation>Memory Allocation<a hidden class=anchor aria-hidden=true href=#memory-allocation>#</a></h2><ul><li><p>Memory allocator</p><ul><li>determines VA to PA mapping</li><li>address translation, page tables
=> simply determine PA from VA and check validity/permsissions</li></ul></li><li><p>Kernel Level Allocators</p><ul><li>kernel state, static process state</li></ul></li><li><p>User Level Allocators</p><ul><li>dynamic process state (heap), malloc/free</li><li>e.g. d/malloc, jemalloc, Hoard, tcmalloc</li></ul></li></ul><h2 id=demand-paging>Demand Paging<a hidden class=anchor aria-hidden=true href=#demand-paging>#</a></h2><ul><li>Virtual Memory &#187; Physical Memory<ul><li>virtual memory page is not always in physical memory</li><li>physical page frame saved and restored to/from secondary storage</li></ul></li></ul><h3 id=demand-paging-1>Demand paging:<a hidden class=anchor aria-hidden=true href=#demand-paging-1>#</a></h3><ul><li>pages swapped in/out of memory & a swap partition (e.g. on a disk)</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/demandpaging.png alt=demandpaging.png></p><ul><li>Original PA != PA after swapping<ul><li>if page is &ldquo;pinned&rdquo;, swapping is disabled</li></ul></li></ul><h4 id=when-pages-should-be-swapped>When pages should be swapped?<a hidden class=anchor aria-hidden=true href=#when-pages-should-be-swapped>#</a></h4><ul><li>page(out) daemon</li><li>when memory usage is above threshold</li><li>when CPU usage is below threshold</li></ul><h4 id=which-page-should-be-swapped-out>Which page should be swapped out?<a hidden class=anchor aria-hidden=true href=#which-page-should-be-swapped-out>#</a></h4><ul><li>pages that won&rsquo;t be used</li><li>history based prediction<ul><li>Least Recently Used (LRU policy). Access bit tracks if page is referenced.</li></ul></li><li>page that don&rsquo;t need to be written out<ul><li>Dirty bit to track if modified</li></ul></li><li>avoid non-swappable pages</li></ul><h2 id=checkpointing>Checkpointing<a hidden class=anchor aria-hidden=true href=#checkpointing>#</a></h2><ul><li>Failure and Recovery management technique<ul><li>periodically save process state</li><li>failure may be unavoidable but can restart from checkpoint, so recovery would be faster</li></ul></li></ul><h4 id=simple-approach>Simple Approach<a hidden class=anchor aria-hidden=true href=#simple-approach>#</a></h4><ul><li>pause and save</li></ul><h4 id=better-approach>Better Approach<a hidden class=anchor aria-hidden=true href=#better-approach>#</a></h4><ul><li>write-protect and copy everything at once</li><li>copy diffs of dirties pages for incremental checkpoints<ul><li>rebuild from multiple diffs, or in background</li></ul></li></ul><p>Checkpointing can also be used in other services:</p><ul><li><p>Debugging</p><ul><li>Rewind-Replay</li><li>rewind = restart from checkpoint</li><li>gradually go back to earlier checkpoints until error is found</li></ul></li><li><p>Migration</p><ul><li>continue on another machine</li><li>disaster recovery</li><li>consolidation</li><li>repeated checkpoints in a fast loop until pause and copy becomes acceptable (or unavoidable)</li></ul></li></ul><hr><h1 id=inter-process-communication-1>Inter Process Communication<a hidden class=anchor aria-hidden=true href=#inter-process-communication-1>#</a></h1><ul><li>Processes share memory<ul><li>data in shared messages</li></ul></li><li>Processes exchange messages<ul><li>message passing via sockets</li></ul></li><li>Requires synchronization<ul><li>mutex, waiting</li></ul></li></ul><p><strong>Inter Process Communication</strong>(IPC) is an OS supported mechanism for interaction among processes (coordination and communication)</p><ul><li>Message Passing<ul><li>e.g. sockets, pips, msgs, queues</li></ul></li><li>Memory based IPC<ul><li>shared memory, memory mapped files</li></ul></li><li>Higher level semantics<ul><li>files, <a href=https://en.wikipedia.org/wiki/Remote_procedure_call>RPC</a></li></ul></li><li>Synchronization primitives</li></ul><h2 id=message-passing>Message Passing<a hidden class=anchor aria-hidden=true href=#message-passing>#</a></h2><ul><li>Send/Receive messages</li><li>OS creates and maintains a channel<ul><li>buffer, FIFO queue</li></ul></li><li>OS provides interfaces to processes<ul><li>a port</li><li>processes send/write messages to this port</li><li>processes receive/read messages from this port</li></ul></li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/messagepassingipc.png alt=messagepassingipc.png></p><ul><li>Kernel required to<ul><li>establish communication</li><li>perform each IPC operation</li><li>send: system call + data copy</li><li>receive: system call + data copy</li></ul></li><li>Request-response:
4x user/ kernel crossings +<br>4x data copies</li></ul><p><strong>Advantages</strong><br></p><ul><li>simplicity : kernel does channel management and synchronization</li></ul><p><strong>Disadvantages</strong><br></p><ul><li>Overheads</li></ul><h3 id=forms-of-message-passing-ipc>Forms of Message Passing IPC<a hidden class=anchor aria-hidden=true href=#forms-of-message-passing-ipc>#</a></h3><h4 id=1-pipes>1. Pipes<a hidden class=anchor aria-hidden=true href=#1-pipes>#</a></h4><ul><li>Carry byte stream between 2 process</li><li>e.g connect output from 1 process to input of another</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/pipes.png alt=pipes.png></p><h4 id=2-message-queues>2. Message queues<a hidden class=anchor aria-hidden=true href=#2-message-queues>#</a></h4><ul><li>Carry &ldquo;messages&rdquo; among processes</li><li>OS management includes priorities, scheduling of message delivery</li><li>APIs : Sys-V and POSIX</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/msgq.png alt=msgq.png></p><h4 id=3-sockets>3. Sockets<a hidden class=anchor aria-hidden=true href=#3-sockets>#</a></h4><ul><li>send() and recv() : pass message buffers</li><li>socket() : create kernel level socket buffer</li><li>associated neccessary kernel processing (TCP-IP,..)</li><li>If different machines, channel between processes and network devices</li><li>If same machine, bypass full protocol stack</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/sockets.png alt=sockets.png></p><h2 id=shared-memory-ipc>Shared Memory IPC<a hidden class=anchor aria-hidden=true href=#shared-memory-ipc>#</a></h2><ul><li>read and write to shared memory region</li><li>OS establishes shared channel between the processes<ol><li>physical pages mapped into virtual address space</li><li>VA(P1) and VA(P2) map to same physical address</li><li>VA(P1) != VA(P2)</li><li>physical mempry doesn&rsquo;t need to be contiguous</li></ol></li><li>APIs : SysV, POSIX, memory mapped files, Android ashmem</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/sharedmemoryipc.png alt=sharedmemoryipc.png></p><p><strong>Advantages</strong><br></p><ul><li>System calls only for setup data copies potentially reduced (but not eliminated)</li></ul><p><strong>Disdvantages</strong><br></p><ul><li>explicit synchronization</li><li>communication protocol, shared buffer management<ul><li>programmer&rsquo;s responsibility</li></ul></li></ul><h2 id=which-is-better>Which is better?<a hidden class=anchor aria-hidden=true href=#which-is-better>#</a></h2><p><strong>Overheads for</strong></p><ol><li>Message Passing : must perform multiple copies</li><li>Shared Memory : must establish all mappings among processes&rsquo; address space and shared memory pages</li></ol><p>Thus, it depends.</p><h2 id=copy-vs-map>Copy vs Map<a hidden class=anchor aria-hidden=true href=#copy-vs-map>#</a></h2><p>Goal for both is to transfer data from one into target saddress space</p><table><thead><tr><th>Copy (Message Passing)</th><th>Map (Shared Memory)</th></tr></thead><tbody><tr><td>CPU cycles to copy data to/from port</td><td>CPU cycles to map memory into address space</td></tr><tr><td>CPU to copy data to channel</td><td></td></tr><tr><td>If channel setup once, use many times (good payoff)</td><td></td></tr><tr><td>Can perform well for 1 time use</td><td></td></tr></tbody></table><ul><li>Large Data: t(Copy) &#187; t(Map)<ul><li>e.g. tradeoff exercised in Window &ldquo;Local&rdquo; Procedure Calls (LPC)</li></ul></li></ul><h2 id=shared-memory-and-synchronization>Shared Memory and Synchronization<a hidden class=anchor aria-hidden=true href=#shared-memory-and-synchronization>#</a></h2><p>Use threads accessing shared state in a single addressing space, but for process</p><p>Synchronization method:</p><ol><li>mechanism supported by processing threading library (pthreads)</li><li>OS supported IPC for sync</li></ol><p>Either method must coordinate</p><ul><li>no of concurrent access to shared segment</li><li>when data is available and ready for consumption</li></ul><h3 id=ipc-synchronization>IPC Synchronization<a hidden class=anchor aria-hidden=true href=#ipc-synchronization>#</a></h3><table><thead><tr><th>Message Queues</th><th>Semaphores</th></tr></thead><tbody><tr><td>Implement &ldquo;mutual exclusion&rdquo; via send/receive</td><td>OS supported synchronization construct</td></tr><tr><td>binary construct (either allow process or not)</td><td></td></tr><tr><td>Like mutex, if value = 0, stop; if value = 1, decrement(lock) and proceed</td><td></td></tr></tbody></table><hr><h1 id=synchronization>Synchronization<a hidden class=anchor aria-hidden=true href=#synchronization>#</a></h1><p>Waiting for other processes, so that they can continue working together</p><ul><li>may repeatedly check to continue<ul><li>sync using spinlocks</li></ul></li><li>may wait for a signal to continue<ul><li>sync using mutexes and condition vatiables</li></ul></li><li>waiting hurts performance<ul><li>CPUs wste cycles for checking; cache effects</li></ul></li></ul><h2 id=limitation-of-mutextes-and-condition-variables>Limitation of mutextes and condition variables<a hidden class=anchor aria-hidden=true href=#limitation-of-mutextes-and-condition-variables>#</a></h2><ul><li>Error prone/correctness/ease of use<ul><li>unlock wrong mutex, signal wrong condition variable</li></ul></li><li>Lack of expressive power<ul><li>helper variables for access or priority control</li></ul></li></ul><p>Low-level support: hardware atmoic instructions</p><h2 id=synchronization-constructs>Synchronization constructs<a hidden class=anchor aria-hidden=true href=#synchronization-constructs>#</a></h2><ol><li>Spinlocks (basic sync construct)<ul><li>Spinlock is like a mutex<ul><li>mutual exclusion</li><li>lock and unlock(free)
- but, lock == busy => spinning</li></ul></li></ul></li><li>Semaphores<ul><li>common sync construct in OS kernels</li><li>like a traffic light: Stop and Go</li><li>like mutex, but more general</li></ul></li></ol><p>Semaphore == integer value</p><ul><li>on init<ul><li>assigned a max value (positive int) => max count</li></ul></li><li>on try(wait)<ul><li>if non-zero, decrement and proceed => counting semaphore</li></ul></li><li>if initialized with 1<ul><li>semaphore == mutex(binary semaphore)</li></ul></li><li>on exit(post)<ul><li>increment</li></ul></li></ul><h2 id=syncing-different-types-of-accesses>Syncing different types of accesses<a hidden class=anchor aria-hidden=true href=#syncing-different-types-of-accesses>#</a></h2><h3 id=readerwriter-locks>Reader/Writer locks<a hidden class=anchor aria-hidden=true href=#readerwriter-locks>#</a></h3><table><tr><td>read (don't modify)</td><td>write (always modify)</td></tr><tr><td>shared access</td><td>exclusive access</td></tr></table><ul><li>RW locks<ul><li>specify type of access, then lock behaves accordingly</li></ul></li></ul><h3 id=monitors-highlevel-construct>Monitors (highlevel construct)<a hidden class=anchor aria-hidden=true href=#monitors-highlevel-construct>#</a></h3><ul><li>shared resource</li><li>entry resource</li><li>possible condition variables</li></ul><ul><li>On entry:<ul><li>lock, check</li></ul></li><li>On exit:<ul><li>unlock, check, signal</li></ul></li></ul><h3 id=more-synchroniaztion-constructs>More synchroniaztion constructs<a hidden class=anchor aria-hidden=true href=#more-synchroniaztion-constructs>#</a></h3><ul><li>serializers</li><li>path expressions</li><li>barriers</li><li>rendezvous points</li><li>optimistic wait-free sync (RCU) [Read Copy Update]</li></ul><p>All need hardware support.</p><h2 id=need-for-hardware-support>Need for hardware support<a hidden class=anchor aria-hidden=true href=#need-for-hardware-support>#</a></h2><ul><li>Problem<ul><li>concurrent check/update on different CPUs can overlap</li></ul></li></ul><h3 id=atomic-instructions>Atomic instructions<a hidden class=anchor aria-hidden=true href=#atomic-instructions>#</a></h3><p>Critical section with hardware supported synchronization</p><h4 id=hardware-specific>Hardware specific<a hidden class=anchor aria-hidden=true href=#hardware-specific>#</a></h4><ul><li><p>test-and-set</p><ul><li>returns(tests) original values and sets new-value!= 1 (busy) automatically</li><li>first thread: test-and-set(lock) => 0 : free</li><li>next ones: test-and-set(lock) => 1 busy<ul><li>reset lock to 1, but that&rsquo;s okay</li></ul></li><li><strong>+</strong> : Latency</li><li><strong>+</strong> : minimal (Atomic)</li><li><strong>+</strong> : Delay potentially min</li><li><strong>-</strong> : Contention processors go to memory on each spin
- To reduce contention, introduce delay
- Static(based on a fixed value) or Dynamic(backoff based, random delay)</li></ul></li><li><p>read-and-increment</p></li><li><p>compare-and-swap</p></li></ul><h4 id=guarantees>Guarantees<a hidden class=anchor aria-hidden=true href=#guarantees>#</a></h4><ul><li>atomicity</li><li>mutual exclusion</li><li>queue all concurrent instructions but one</li></ul><h3 id=shared-memory-multiprocessors>Shared Memory Multiprocessors<a hidden class=anchor aria-hidden=true href=#shared-memory-multiprocessors>#</a></h3><p>Also called symmetric multiprocessors (SMP)</p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/sharedmmmp.png alt=sharedmmmp></p><ul><li>Caches<ul><li>hide memory latency, &ldquo;memory&rdquo; further away due to contention</li><li>no-write, write-through, write-back</li></ul></li></ul><h3 id=cache-coherence>Cache Coherence<a hidden class=anchor aria-hidden=true href=#cache-coherence>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/cachecoherence.png alt=cachecoherence></p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/cachecoherence2.png alt=cachecoherence2></p><hr><pre><code># I/O Management
</code></pre><p>Operating system</p><ul><li>Has protocols<ul><li>Interfaces for device I/O</li></ul></li><li>Has dedicated handlers<ul><li>Device drivers, interrupt handlers</li></ul></li><li>Decouple I/O details from core processing<ul><li>abstract I/O device detail from applications</li></ul></li></ul><h2 id=io-device-features>I/O Device Features<a hidden class=anchor aria-hidden=true href=#io-device-features>#</a></h2><ul><li>Control registers (accessed by CPU)<ul><li>Command</li><li>Data Transfers</li><li>Status</li></ul></li><li>Microcontroller : device&rsquo;s CPU</li><li>On device memory</li><li>Other logic<ul><li>e.g. analog to digital</li></ul></li></ul><h2 id=device-drivers>Device drivers<a hidden class=anchor aria-hidden=true href=#device-drivers>#</a></h2><ul><li>per each device type</li><li>responsible for device access management and control</li><li>provided by device manufacturers per OS /version</li><li>each OS standardizes interfaces<ul><li>device independence</li><li>device diversity</li></ul></li></ul><h2 id=types-of-devices>Types of devices<a hidden class=anchor aria-hidden=true href=#types-of-devices>#</a></h2><ul><li>Block<ul><li>e.g. disk</li><li>read/write blocks of data</li><li>direct access to arbitrary block</li></ul></li><li>Character<ul><li>e.g. keyboard</li><li>get/put character</li></ul></li><li>Network devices</li></ul><p>OS representation of a device : special device file</p><p>UNIX like systems:</p><ul><li>/dev</li><li>tmpfs</li><li>devfs</li></ul><p>Linux supports a number of pseudo &ldquo;virtual&rdquo; devices that provide special functionality to a system.</p><h2 id=cpu-device-interactions>CPU device interactions<a hidden class=anchor aria-hidden=true href=#cpu-device-interactions>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/iointeractions.png alt=iointeractions.png></p><p>access device registers : memory load/store</p><ol><li>Memory mapped I/0<ul><li>part of &lsquo;host&rsquo; physical memory dedicated for device interactions</li><li>Base Address Registers (BAR)</li></ul></li><li>I/O Port<ul><li>dedicated in low instructions for device access</li><li>target device (I/0 port) and value in register</li></ul></li></ol><h2 id=path-from-device-to-cpu>Path from Device to CPU<a hidden class=anchor aria-hidden=true href=#path-from-device-to-cpu>#</a></h2><ol><li>Interrupt<ul><li>Overhead: Interrupt handling steps</li><li>+: Can be generated as soon as possible</li></ul></li><li>Polling<ul><li>Overhead: Delay or CPU overhead</li><li>when convenient for OS</li></ul></li></ol><h2 id=device-access--programmed-io-pio>Device access : Programmed I/O (PIO)<a hidden class=anchor aria-hidden=true href=#device-access--programmed-io-pio>#</a></h2><ul><li>No additional hardware support</li><li>CPU &ldquo;programs&rdquo; the device<ul><li>via command registers</li><li>data movement</li></ul></li><li>E.g. NIC(Network Interface Card)<ul><li>data = network packet</li></ul></li><li>Write command to request packet information</li><li>Copy packet to data registers</li><li>Repeat until packet sent</li></ul><p>E.g. 1500B packet; 8 byte registers or bus => 1(for bus command) + 188(for data) = 189 CPU store instructions</p><h2 id=direct-memory-access-dma>Direct Memory Access (DMA)<a hidden class=anchor aria-hidden=true href=#direct-memory-access-dma>#</a></h2><ul><li>Relies on DMA controller</li><li>CPU &ldquo;programs&rdquo; the device<ul><li>via command registers</li><li>via DMA controls</li></ul></li><li>E.g. NIC (data = network packet)</li><li>Write command to request packet information</li><li>Configure DMA controller with in memory address and size of packet buffer</li></ul><p>E.g. 1500B packet; 8 byte registers or bus => 1(for bus command) + 1(for DMA configuration) = total 2 CPU store instructions. Less steps, but DMA configuration is more complex.</p><p>For DMAs</p><ul><li>data buffer must be in physical memory until transfer completes</li><li>pinning regions (non-swappable)</li></ul><h2 id=typical-device-access>Typical Device Access<a hidden class=anchor aria-hidden=true href=#typical-device-access>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/typicaldeviceaccess.png alt=typicaldeviceaccess.png></p><ul><li>System call</li><li>In-kernel stack</li><li>Driver Invocation</li><li>Device request configuration</li><li>Device performs request</li></ul><h3 id=os-bypass>OS bypass<a hidden class=anchor aria-hidden=true href=#os-bypass>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/osbypass.png alt=osbypass.png></p><ul><li>device registers/data<ul><li>directly available</li></ul></li><li>OS configures<ul><li>then gets out of the way</li></ul></li><li>&ldquo;user level driver&rdquo;<ul><li>in library</li></ul></li><li>OS retains coarse-grain control</li><li>relies on device features<ul><li>sufficient registers</li><li>demux capability</li></ul></li></ul><h2 id=what-happens-to-a-calling-thread>What happens to a calling thread?<a hidden class=anchor aria-hidden=true href=#what-happens-to-a-calling-thread>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/access.png alt=access.png></p><ul><li>Synchronous I/O operations<ul><li>process blocks</li></ul></li><li>Asynchronous I/O operations<ul><li>process continues</li><li>Later, process checks and retrieves result</li><li>OR</li><li>process is notified that operation is completed and results are ready</li></ul></li></ul><h2 id=block-device-stack>Block Device Stack<a hidden class=anchor aria-hidden=true href=#block-device-stack>#</a></h2><p>Block device typical storage for files:</p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/blockdevicestack.png alt=blockdevicestack.png></p><ul><li>processes use files => logical storage unit</li><li>kernel file system (KFS)<ul><li>where how to find and access file</li><li>OS specifies interface</li></ul></li><li>generic block layer<ul><li>OS standardized block interface</li></ul></li><li>Device driver</li></ul><h2 id=virtual-file-system>Virtual File System<a hidden class=anchor aria-hidden=true href=#virtual-file-system>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/vfs.png alt=vfs.png></p><h3 id=virtual-file-system-abstractions>Virtual File System Abstractions<a hidden class=anchor aria-hidden=true href=#virtual-file-system-abstractions>#</a></h3><ul><li>File : Elements on which the VFS operates</li><li>File Descriptor : OS representation of file<ul><li>open, read, write, send file , lock, close</li></ul></li><li>inode : Persistent representation of file &ldquo;index&rdquo;<ul><li>list of all data blocks</li><li>device, permissions, size</li></ul></li><li>dentry : Directory entry, corresponding to the single path component,<ul><li>dentry cache</li></ul></li><li>super block : file system specific information regarding the File System layout</li></ul><h3 id=vfs-on-disk>VFS on disk<a hidden class=anchor aria-hidden=true href=#vfs-on-disk>#</a></h3><ul><li>File : data blocks on disk</li><li>inode : track file blocks<ul><li>also resides on disk in some block</li></ul></li><li>super block : overall map of disk blocks<ul><li>inode blocks</li><li>data blocks</li><li>free blocks</li></ul></li></ul><h3 id=inodes>Inodes<a hidden class=anchor aria-hidden=true href=#inodes>#</a></h3><p>Index of all disk blocks corresponding to a file</p><ul><li>File : identified by inode</li><li>inode : list of all blocks + other metadata</li></ul><p><strong>+</strong>: Easy to perform sequential or random access<br><strong>-</strong>: Limit on file size</p><h3 id=inodes-with-indirect-pointers>Inodes with indirect pointers<a hidden class=anchor aria-hidden=true href=#inodes-with-indirect-pointers>#</a></h3><ul><li>Index of all disk blocks corresponding to a file</li><li>Index contain:<ul><li>metadata</li><li>pointers to blocks</li></ul></li><li>Direct pointer : Points to data block<ul><li>1 KB per entry</li></ul></li><li>Indirect pointer : Points to block of pointers<ul><li>256 KB per entry</li></ul></li><li>Double Indirect pointer : Points to block of block of pointers<ul><li>64 MB per entry</li></ul></li></ul><p><strong>+</strong>: Small inode => large file size<br><strong>-</strong>: File access slowdown</p><h2 id=disk-access-optimizations>Disk access optimizations<a hidden class=anchor aria-hidden=true href=#disk-access-optimizations>#</a></h2><p>Reducing file access overheads</p><ol><li>Caching/buffering : reducenumber of disk accesses<ul><li>buffer cache in main menu</li><li>read/write from cache</li><li>periodically flush to disk - fsync()</li></ul></li><li>I/O scheduling : reduce disk head movement<ul><li>maximize sequential vs random access</li></ul></li><li>Prefetching : increases cache hits<ul><li>leverages locality</li></ul></li><li>Journaling/logging: reduce random access (ext3, ext4)<ul><li>&ldquo;describe&rdquo; write in log : block, offset, value..</li><li>periodically apply updates to proper disk locations</li></ul></li></ol><hr><pre><code># Virtualization
</code></pre><p>Virtualization allows concurrent execution of multiple OSs and their applications on the same physical machine.</p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/virtualization.png alt=virtualization.png></p><ul><li>Virtual resources : each OS thinks that ot &ldquo;owns&rdquo; hardware resources</li><li>Virtual machine (VM) : OS + applications + virtual resources (guest domain)</li><li>Virtualization layer : management of physical hardware (virtual machine monitor, hypervisor)</li></ul><h2 id=defining-virtual-machine>Defining Virtual Machine<a hidden class=anchor aria-hidden=true href=#defining-virtual-machine>#</a></h2><p>A Virtual Machine is an efficient, isolated duplicate of the real machine.</p><ul><li>Supported by a Virtual Machine Monitor (VMM):<ol><li>provides environment essentially identical with the original machine</li><li>programs show only minor decrease in speed at worst</li><li>VMM is in complete control of the system resources</li></ol></li></ul><h2 id=vmm-goals>VMM goals<a hidden class=anchor aria-hidden=true href=#vmm-goals>#</a></h2><ul><li>Fidelity</li><li>Performance</li><li>Safety and Isolation</li></ul><h2 id=virtualization-advantages>Virtualization advantages<a hidden class=anchor aria-hidden=true href=#virtualization-advantages>#</a></h2><ul><li>consolidation<ul><li>decrease cost, improve manageability</li></ul></li><li>migration<ul><li>availibility, reliability</li></ul></li><li>security, debugging, support for legacy OS</li></ul><h2 id=two-main-virtualization-models>Two main Virtualization Models:<a hidden class=anchor aria-hidden=true href=#two-main-virtualization-models>#</a></h2><h3 id=1-bare-metal-or-hypervisor-based-type-1>1. Bare-metal or Hypervisor based (Type 1)<a hidden class=anchor aria-hidden=true href=#1-bare-metal-or-hypervisor-based-type-1>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/hypervisor.png alt=hypervisor.png></p><ul><li>VMM (hypervisor) manages all hardware resources abd supports execution of VMs</li><li>privileged, secure VM to deal with devices (and other configuration and management tasks)</li><li>Adopted by Xen(Opensource or Citriol Xen Server) and ESX (VMware)</li></ul><h3 id=1-hosted-type-2>1. Hosted (Type 2)<a hidden class=anchor aria-hidden=true href=#1-hosted-type-2>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/hosted.png alt=hosted.png></p><ul><li>Host owns all hardware</li><li>Special VMM modle provides hardware interfaces to VMs and deals with VM context switching</li></ul><h2 id=virtualization-requirements>Virtualization requirements<a hidden class=anchor aria-hidden=true href=#virtualization-requirements>#</a></h2><ul><li>Present virtual platform interface to VMs<ul><li>virtualize CPU, memory, devices</li></ul></li><li>Provide isolation across VMs<ul><li>preemption, MMU for address translation and validation</li></ul></li><li>Protect guest OS from applications<ul><li>can&rsquo;t run guest OS and applications at same protection level</li></ul></li><li>Protect VMs from guest OS<ul><li>can&rsquo;t run guest OS and VMMs at same protection level</li></ul></li></ul><h2 id=hardware-protection-levels>Hardware protection levels<a hidden class=anchor aria-hidden=true href=#hardware-protection-levels>#</a></h2><p>Commodity hardware has more than two protection levels</p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/hwprotectionlevels.png alt=hwprotectionlevels></p><ul><li>x86 has 4 protection levels (rings)<ul><li>ring 3 : lowest privilege (applications)</li><li>ring 1 : OS</li><li>ring 0 : highest privilege (hypervisor)</li></ul></li><li>and 2 protection modes<ul><li>non root : VMs<ul><li>ring 3 : apps</li><li>ring 0 : OS</li></ul></li><li>root :<ul><li>ring 0 : hypervisor</li></ul></li></ul></li></ul><h2 id=process-virtualization-trap-and-emulate>Process Virtualization (Trap-and-Emulate)<a hidden class=anchor aria-hidden=true href=#process-virtualization-trap-and-emulate>#</a></h2><ul><li>Guest instruments<ul><li>executed directly by hardware</li><li>for non-privileged operations : hardware speeds => efficiency</li><li>for privileged operations : trap to hypervisor</li></ul></li><li>Hypervisor determines what needs to be done:<ul><li>if illegal operation : terminate VM</li><li>if legal operation : emulate the behaviour the guest OS was expecting from the hardware</li></ul></li></ul><h2 id=problems-with-trap-and-emulate>Problems with Trap-and-Emulate<a hidden class=anchor aria-hidden=true href=#problems-with-trap-and-emulate>#</a></h2><ul><li>17 privileged information do not trao but fail silently</li><li>Hypervisor doesn&rsquo;t know, so it doesn&rsquo;t try to change settings</li><li>OS doesn&rsquo;t know, so assumes change was successful</li></ul><h2 id=binary-translation>Binary Translation<a hidden class=anchor aria-hidden=true href=#binary-translation>#</a></h2><p><strong>Goal</strong> : Full Virtualization i.e. guest OS is not modified</p><p><strong>Approach</strong> : Dynamic Binary Translation</p><ol><li>Inspect code blocks to be executed</li><li>If needed, translate to alternate instruction sequence<ul><li>e.g. to emulate desired behaviour, possibly avoid traps</li></ul></li><li>Otherwise run at hardware speeds<ul><li>cache translated blocks to ammortize translation costs</li></ul></li></ol><h2 id=paravirtualization>Paravirtualization<a hidden class=anchor aria-hidden=true href=#paravirtualization>#</a></h2><p><strong>Goal</strong> : Performance; give up on modified guest OSs</p><p><strong>Approach</strong> : Paravirtualization : modify guest OSs so that</p><ul><li>it knows it is running virtualized</li><li>it makes explicit calls to hyperisor (hypercalls)</li><li>hypercalls (~ system calls)<ul><li>package context information</li><li>specify desired hypercall</li><li>trap to VMM</li></ul></li><li>Xen : opensource hypervisor</li></ul><h2 id=memory-virtualization>Memory virtualization<a hidden class=anchor aria-hidden=true href=#memory-virtualization>#</a></h2><ul><li>Full virtualization<ul><li>all guests expect contiguous physical memory starting at 0</li><li>virtual vs physical vs machine addresses and page frame numbers</li><li>still leverages hardware (MMU, TLB..)</li></ul></li><li>Option 1<ul><li>guest page table : VA => PA</li><li>hypervisor : PA => MA</li><li>too expensive!</li></ul></li><li>Option 2<ul><li>guest page tables : VA => PA</li><li>hypervisor shadow PT : VA => MA</li><li>hypervisor maintains consistence<ul><li>e.g. invalidate on context switch, write protect guest PT to track new mappings</li></ul></li></ul></li><li>Paravirtualized<ul><li>guest aware of virtualization</li><li>no longer strict requirement on contiguous physical memory starting at 0</li><li>explicitly registers page tables with hypervisor</li><li>can &ldquo;batch&rdquo; page tables updates to reduce VM exits</li><li>other optimazations</li></ul></li></ul><p>Overheads eliminated or reduced on newer platforms</p><h2 id=device-virtualization>Device Virtualization<a hidden class=anchor aria-hidden=true href=#device-virtualization>#</a></h2><ul><li>For CPUs and Memory<ul><li>less diversity, Intruction-Set-Architecture(ISA) level</li><li>Standardization of interface</li></ul></li><li>For Devices<ul><li>high diversity</li><li>lack of standard specification of device interface and behaviour</li></ul></li></ul><h4 id=3-key-models-for-device-virtualization>3 key models for Device Virtualization:<a hidden class=anchor aria-hidden=true href=#3-key-models-for-device-virtualization>#</a></h4><h3 id=1-pass-through-model>1. Pass through model<a hidden class=anchor aria-hidden=true href=#1-pass-through-model>#</a></h3><p>Approach: VMM-level-driver configures device access permissions</p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/passthrough.png alt=passthrough.png></p><p><strong>Advantages</strong><br></p><ul><li>VM provided with exclusive and direct (VMM bypass) access to the device</li></ul><p><strong>Disadvantages</strong><br></p><ul><li>Device sharing difficult</li><li>VMM must have exact type of device as what VM expects</li><li>VM migration tricky</li></ul><h3 id=2-hypervisor---direct-model>2. Hypervisor - Direct model<a hidden class=anchor aria-hidden=true href=#2-hypervisor---direct-model>#</a></h3><p>Approach:</p><ul><li>VMM interrupts all device accesses</li><li>Emulate device operations<ul><li>translate to generic I/O operations</li><li>traverse VMM-resident I/O stack</li><li>invoke VMM-resident driver</li></ul></li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/hypervisordirect.png alt=hypervisordirect.png></p><p><strong>Advantages</strong><br></p><ul><li>VM decoupled from physical device</li><li>Sharing, migration, dealing with device specifics</li></ul><p><strong>Disadvantages</strong><br></p><ul><li>Latency of device operations</li><li>Device driver ecosystem complexities in Hypervisor</li></ul><h3 id=3-split-device-driver-model>3. Split Device-Driver model<a hidden class=anchor aria-hidden=true href=#3-split-device-driver-model>#</a></h3><p>Approach:</p><ul><li>Device access control split between</li><li>Emulate device operations<ul><li>front-end driver in guest VM (device API)</li><li>back-end driver in service VM (or Host)</li><li>modified guest drivers<ul><li>i.e. limited to paravirtualized guests</li></ul></li></ul></li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/splitdevicedriver.png alt=splitdevicedriver.png></p><p><strong>Advantages</strong><br></p><ul><li>Eliminate emulation overhead</li><li>Allow for better management of shared devices</li></ul><hr><h1 id=remote-procedure-calls>Remote Procedure Calls<a hidden class=anchor aria-hidden=true href=#remote-procedure-calls>#</a></h1><p>Example : GetFile App</p><ul><li>Client Server</li><li>Create and init sockets</li><li>Allocate and populate buffers</li><li>Include &lsquo;protocol&rsquo; info<ul><li>GetFile, size</li></ul></li><li>Copy data into buffers<ul><li>filename, file</li></ul></li></ul><ul><li>common steps related to remote IPC</li></ul><h4 id=remote-procedure-calls-rpc>Remote Procedure Calls (RPC)<a hidden class=anchor aria-hidden=true href=#remote-procedure-calls-rpc>#</a></h4><ul><li>Intended to simplify the development of cross address space and cross machine interactions</li></ul><p><strong>+</strong> Higher-level interface for data movement and communication<br><strong>+</strong> Error handling<br><strong>+</strong> Hiding complexities of cross machine interactions</p><h2 id=rpc-requirements>RPC requirements<a hidden class=anchor aria-hidden=true href=#rpc-requirements>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/rpcrequirements.png alt=rpcrequirements></p><ol><li>Client/Server interactions</li><li>Procedure Call Interface => RPC<ul><li>sync call semantics</li></ul></li><li>Type checking<ul><li>error handling</li><li>packet bytes interpretation</li></ul></li><li>Cross machine conversion<ul><li>e.g. big/little endian</li></ul></li><li>Higher level protocol<ul><li>access control, fault tolerance, different transport protocols</li></ul></li></ol><h2 id=structure-of-rpc>Structure of RPC<a hidden class=anchor aria-hidden=true href=#structure-of-rpc>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/rpcstructure.png alt=rpcstructure></p><h2 id=rpc-steps>RPC Steps:<a hidden class=anchor aria-hidden=true href=#rpc-steps>#</a></h2><p>(-1.) register : server registers procedure, arg types, location<br>(0.) bind : client finds and binds to desired server</p><ol><li>call : client make RPC call; control passed to stub, client code blocks</li><li>marshal : client stub &ldquo;marshals&rdquo; args (serialize args into buffer)</li><li>send : client sends message to server</li><li>receive : server receives message; passes message to server stub; access control</li><li>unmarshal : server stub &ldquo;unmarshals&rdquo; args (extract args from buffer)</li><li>actual call : server stub calls local procedure implementation</li><li>result : server performs operation and computes result of RPC operation</li></ol><p>(same on return &lt;=)</p><h2 id=interface-definition-language-idl>Interface definition Language (IDL)<a hidden class=anchor aria-hidden=true href=#interface-definition-language-idl>#</a></h2><ul><li>Used to describe the interface the server expects<ul><li>procedure name, args, 2 result types</li><li>version number</li></ul></li></ul><p>RPC can use IDL that is</p><ol><li>Language agnostic<ul><li>XDR in SunRPC</li></ul></li><li>Language specific<ul><li>Java in JavaRMI</li></ul></li></ol><h2 id=marshalling>Marshalling<a hidden class=anchor aria-hidden=true href=#marshalling>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/marshalling.png alt=Marshalling></p><h2 id=unmarshalling>Unmarshalling<a hidden class=anchor aria-hidden=true href=#unmarshalling>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/unmarshalling.png alt=Unmarshalling></p><p>Marshalling/Unmarshalling routines are provided by RPC system compiler.</p><h2 id=binding-and-registry>Binding and Registry<a hidden class=anchor aria-hidden=true href=#binding-and-registry>#</a></h2><ul><li>Client determines<ul><li><strong>which</strong> server to connect to?<ul><li>service name. version number</li></ul></li><li><strong>how</strong> to connect to that server?<ul><li>IP address, network protocol</li></ul></li></ul></li><li>Registry : database of available services<ul><li>search for service name to find server(which) and contact details(how)</li><li>distributed<ul><li>any RPC service can register</li></ul></li><li>machine-specific<ul><li>for services running on same machine</li><li>clients must know machine addresses</li><li>registry provides port number needed for connection</li></ul></li></ul></li><li>Who can provide a service?<ul><li>lookup registry for image processing</li></ul></li><li>What services do they provide?<ul><li>compress/filter.. version number => IDL</li></ul></li><li>How will they ship package?<ul><li>TCP / UDP -> registry</li></ul></li></ul><h2 id=pointers>Pointers<a hidden class=anchor aria-hidden=true href=#pointers>#</a></h2><ul><li>Procedure interface : foo(int,int)</li><li>in Local Calls : foo(x,y) => okay</li><li>in Remote Calls : foo(x,y) => ?</li></ul><p>here, y points to location in caller address space</p><ul><li>Solutions:<ul><li>No pointers</li><li>Serialize pointers; copy referenced (&ldquo;points to&rdquo;) data structure to send buffer</li></ul></li></ul><h2 id=handling-partial-failures>Handling Partial Failures<a hidden class=anchor aria-hidden=true href=#handling-partial-failures>#</a></h2><ul><li>Special RPC error notification (signal, exception..)<ul><li>Catch all possible ways in which RPC can (partially) fail</li></ul></li></ul><h2 id=rpc-design-choice>RPC Design choice<a hidden class=anchor aria-hidden=true href=#rpc-design-choice>#</a></h2><ul><li>Binding => How to find the server</li><li>IDL => How to talk to server; how to package data</li><li>Pointers as args => Disallow or serialize pointer data</li><li>Partial failures => Special error notifications</li></ul><hr><h1 id=distributed-file-systems>Distributed File Systems<a hidden class=anchor aria-hidden=true href=#distributed-file-systems>#</a></h1><ul><li>Accessed via well defined interface<ul><li>access via Virtual File Systems</li></ul></li><li>Focus on consistent state<ul><li>tracking state, file update, cache coherence</li></ul></li><li>Mixed distribution models possible<ul><li>replicates vs partitioned, peer-like systems</li></ul></li></ul><h2 id=dfs-models>DFS models<a hidden class=anchor aria-hidden=true href=#dfs-models>#</a></h2><ul><li>Client Server on different machines</li><li>File server distributed on multiple machines<ul><li>replicated (each server : all files)</li><li>partitioned (each server : parts of files)</li><li>both (files partitioned, each partition replicates)</li></ul></li><li>Files stored on and served from all machines (peers)<ul><li>blurred distinction between clients and servers</li></ul></li></ul><h2 id=remote-file-service--extremes>Remote File Service : Extremes<a hidden class=anchor aria-hidden=true href=#remote-file-service--extremes>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/extremes.png alt=extremes></p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/extremes2.png alt=extremes2></p><ol><li>Extreme1 : Upload/Download<ul><li>like FTP, SVN</li><li><strong>+</strong> local read/writes at client</li><li><strong>-</strong> entire file download/upload evn for small accesses</li><li><strong>-</strong> server gives up contro;</li></ul></li><li>Extreme2 : True Remote File Access<ul><li>Every access to remote file, nothing done locally</li><li><strong>+</strong> file access centralized, easy to reason about consistency</li><li><strong>-</strong> every file operation pays network cost, limits server scalablity</li></ul></li></ol><h2 id=remote-file-service--a-compromise>Remote File Service : A compromise<a hidden class=anchor aria-hidden=true href=#remote-file-service--a-compromise>#</a></h2><p>A more practical Remote File access (with Caching)</p><ol><li>Allow clients to store parts of files locally (blocks)<ul><li><strong>+</strong> low latency on file operations</li><li><strong>+</strong> server load reduces => more scalable</li></ul></li><li>Force clients to interact with server (frequently)<ul><li><strong>+</strong> server has insights into what clients are doing</li><li><strong>+</strong> server has control into which accesses can be permitted => easier to maintain consistency</li><li><strong>-</strong> server more complex, requires different file sharing semantics</li></ul></li></ol><h2 id=stateless-vs-stateful-file-server>Stateless vs Stateful File server<a hidden class=anchor aria-hidden=true href=#stateless-vs-stateful-file-server>#</a></h2><table><thead><tr><th>Stateless</th><th>Stateful</th></tr></thead><tbody><tr><td>Keeps no state; Okay with extreme models, but can&rsquo;t support &lsquo;practical&rsquo; model</td><td>Keeps client state needed for &lsquo;practical&rsquo; model to track what is cached/accessed</td></tr><tr><td><strong>-</strong> Can&rsquo;t support caching and consistency management</td><td><strong>+</strong> Can support locking, caching, incremental operations</td></tr><tr><td><strong>-</strong> Every request self-contained. => more bits transferred</td><td><strong>-</strong> Overheads to maintain state and consistency. Depends on caching mechanism and consistency protocol.</td></tr><tr><td><strong>+</strong> No resources are used on server side (CPU, MM). On failure just restart</td><td><strong>-</strong> On failure, need checkpoining and recovery mechanisms</td></tr></tbody></table><h2 id=caching-state-in-a-dfs>Caching state in a DFS<a hidden class=anchor aria-hidden=true href=#caching-state-in-a-dfs>#</a></h2><ul><li>Locally clients maintain portion of state (e.g. file blocks)</li><li>Locally clients perform operations on cached state (e.g. open/read/write)</li><li>requires coherent mechanisms</li></ul><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/cachingstate.png alt=cachingstate.png></p><table><thead><tr><th>System</th><th>How</th><th>When</th></tr></thead><tbody><tr><td>SMP</td><td>Write-update/Write-invalidate</td><td>On write</td></tr><tr><td>DFS</td><td>Client/Server-driven</td><td>On demand, periodically, on open..</td></tr></tbody></table><ul><li><p>Files or File blocks can be (with 1 server and multiple clients) cached in:</p><ul><li>in client memory</li><li>on client storage device (HDD/SDD)</li><li>in buffer cache in memory on server<ul><li>(usefulness will depend on client load, request interleaving)</li></ul></li></ul></li><li><p>File Sharing Semantics in DFS</p></li><li><p>Session semantics (between open-close => Session)</p><ul><li>write-back on close(), update on open()</li><li>easy to reason, but may be insufficient</li></ul></li><li><p>Periodic updates</p><ul><li>client writes-back periodically<ul><li>clients have a &ldquo;lease&rdquo; on cached data (not exclusively necessary)</li></ul></li><li>servers invalidates periodically => provides biunds on &ldquo;inconsistency&rdquo;</li><li>augment with flush()/sync() API</li></ul></li><li><p>Immutable files => never modify, new files created</p></li><li><p>Transactions => all changes atomic</p></li></ul><h1 id=replication-vs-partitioning>Replication vs Partitioning<a hidden class=anchor aria-hidden=true href=#replication-vs-partitioning>#</a></h1><table><tr><th></th><th>Replication</th><th>Partitioning</th></tr><tr><td></td><td>Each machine holds all files</td><td>Each machine has subset of files</td></tr><tr><td>Advantages</td><td>Load balancing, availibility, fault tolerance</td><td>Availibility vs single server DFS;<br>Scalability with file system size;<br>single file writes simpler</td></tr><tr><td>Disadvantages</td><td>Write becomes more complex<br>- Synchronous to all<br>- or, write to one, then propagate to others<br>replicas must be reconciled e.g. Voting</td><td>On failure, lose portion of data<br>load balancing harder, if not balanced, then hot-spots possible</td></tr></table><ul><li>Can combine both techniques<ul><li>Replicate each partition!</li></ul></li></ul><hr><h1 id=distributed-shared-memory>Distributed Shared Memory<a hidden class=anchor aria-hidden=true href=#distributed-shared-memory>#</a></h1><ul><li>Must decide placement<ul><li>place memory (pages) close to relevant processes</li></ul></li><li>Must decide migration<ul><li>when to copy memory (pages) from remote to local</li></ul></li><li>Must decide sharing rules<ul><li>ensure memory generations are properly ordered</li></ul></li></ul><h2 id=peer-distribution-applications>&ldquo;Peer&rdquo; Distribution Applications<a hidden class=anchor aria-hidden=true href=#peer-distribution-applications>#</a></h2><ul><li>Each node<ul><li>&ldquo;owns&rdquo; state</li><li>provide service</li></ul></li></ul><ul><li>all nodes are &ldquo;peers&rdquo;.</li></ul><p>Examples: Big-data analytics, web searches, context sharing or distributed shared memory (DSM)</p><h2 id=distributed-shared-memory-dsm>Distributed Shared Memory (DSM)<a hidden class=anchor aria-hidden=true href=#distributed-shared-memory-dsm>#</a></h2><p>DSM is a service that manages memory accross multiple nodes so that applications that are running on top will have an illusion that they are running on a shared memory.</p><ul><li>Each node<ul><li>&ldquo;owns&rdquo; state => memory</li><li>provide service<ul><li>memory read/writes from any nodes</li><li>consistency protocols</li></ul></li><li>permits scaling beyond single machine memory limits<ul><li>more &ldquo;shared&rdquo; memory at lower cost</li><li>slower overall memory access</li><li>commodity interconnect technologies support this RDMA(Remote Direct Memory Access)</li></ul></li></ul></li></ul><h2 id=hardware-vs-software-dsm>Hardware vs Software DSM<a hidden class=anchor aria-hidden=true href=#hardware-vs-software-dsm>#</a></h2><ul><li>Hardware-supported (expensive!)<ul><li>relies on interconnect</li><li>OS manages larger physical memory</li><li>NIC(Network Interface Cards) translate remote memory accesses to messages</li><li>NICs involved in all aspects of memory management; support atomics..</li></ul></li><li>Software supported<ul><li>everything done by software</li><li>OS,or language runtime</li></ul></li><li>Hybrid (Software tasks in Hardware) DSM implementations<ul><li>prefetch pages</li><li>address translation (easier done in hardware)</li><li>triggering invalidations (easier done in hardware)</li></ul></li></ul><h2 id=dsm-design--sharing-granularity>DSM Design : Sharing Granularity<a hidden class=anchor aria-hidden=true href=#dsm-design--sharing-granularity>#</a></h2><ul><li>cache line granularity?<ul><li>overheads too high for DSM</li></ul></li></ul><ul><li>variable granularity [N]</li><li>page granularity [Y] (OS level)</li><li>object granularity [Y] (Language runtime)<ul><li>beware of false sharing E.g. x and y shared on same page</li></ul></li></ul><h2 id=what-types-of-applications-use-dsm>What types of applications use DSM?<a hidden class=anchor aria-hidden=true href=#what-types-of-applications-use-dsm>#</a></h2><p>Application access algorithm</p><ul><li>Single reader/ single writer (SRSW)</li><li>Multiple readers/ single writer (MRSW)</li><li>Multiple reader/ Multiple writers (MRMW)</li></ul><h2 id=performance-considerations>Performance considerations<a hidden class=anchor aria-hidden=true href=#performance-considerations>#</a></h2><ul><li>DSM performance metric == access latency</li><li>Achieving low latency through<ul><li>Migration<ul><li>makes sense for SRSW</li><li>requires data movement</li></ul></li><li>Replication (caching)<ul><li>more general</li><li>requires consistency management</li></ul></li></ul></li><li>Hence, migration is okay for SRSW but not for all.</li><li>Caching and Replication<ul><li>Copies of data to incerease data access</li><li>for many concurrent writes, overheads too high but stil generally better than Migration</li></ul></li></ul><h2 id=consistency-management>Consistency Management<a hidden class=anchor aria-hidden=true href=#consistency-management>#</a></h2><ul><li>In SMP<ul><li>write invalidate</li><li>write update</li></ul></li><li>coherence operations triggered in each write<ul><li>overhead too high</li></ul></li><li>Push invalidations when data is written to<ol><li>Proactive</li><li>Eager</li><li>Pessimistic</li></ol></li><li>Pull modifications information periodically<ol><li>on demand (reactive)</li><li>lazy</li><li>optimistic</li></ol></li><li>when these methods get triggered depends on the consistency model for the shared state</li></ul><h2 id=dsm-architecture-page-based-os-supported>DSM architecture (page-based, OS-supported)<a hidden class=anchor aria-hidden=true href=#dsm-architecture-page-based-os-supported>#</a></h2><ul><li>Page-based DSM architecture<ul><li>distributed nodes, each with own local memory contribution</li><li>pool of pages from all nodes</li><li>each page has IO (&ldquo;home&rdquo; node), page frame number</li></ul></li><li>if MRMW<ul><li>need local caches for performances (latency)</li><li>&ldquo;home&rdquo; or &ldquo;manager&rdquo; node drives coherence operations</li><li>all nodes responsible for part if distributed memory (state) management</li></ul></li><li>Home node<ul><li>keeps state: page accessed, modifications, caching enabled/disabled, locked..</li></ul></li><li>Current owner<ul><li>owner may not be equal to home node</li></ul></li><li>Explicit replicas<ul><li>for load balancing, performance, or reliability
home, manager node controls memory</li></ul></li></ul><h2 id=dsm-metadata>DSM metadata<a hidden class=anchor aria-hidden=true href=#dsm-metadata>#</a></h2><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/metadata.png alt=metadata.png></p><h2 id=implementing-dsms>Implementing DSMs<a hidden class=anchor aria-hidden=true href=#implementing-dsms>#</a></h2><ul><li>Problem : DSM must intercept access to DSM state<ul><li>to send remote messages requesting access</li><li>to trigger coherence messages</li></ul></li></ul><ul><li>overheads should be avoided for local non-shared state (pages)</li><li>dynamically engage and disengage DSM when necessary</li></ul><ul><li>Solution : Use hardware MMU support!<ul><li>trap in OS if mapping invalid or access denied</li><li>remote address mapping -> trap and pass to DSM to send message</li><li>cached content -> trap and pass to DSM to perform memory coherence operations</li><li>other MMU information useful (e.g. Dirty page)</li></ul></li></ul><h2 id=consistency-model>Consistency model<a hidden class=anchor aria-hidden=true href=#consistency-model>#</a></h2><ul><li>Agreement between memory (state) and upper software layers</li><li>Memory behaves correctly if and only if software follows specific rules</li><li>Memory (state) guarantees to behave correctly<ul><li>access ordering</li><li>propagation/ visibility of updates</li></ul></li></ul><h3 id=our-notation>Our notation<a hidden class=anchor aria-hidden=true href=#our-notation>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/notation.png alt=notation.png></p><ul><li>R_m1(X) => X was read from memory location m1</li><li>W_m1(Y) => Y was written to memory location m1</li></ul><h3 id=strict-consistency>Strict Consistency<a hidden class=anchor aria-hidden=true href=#strict-consistency>#</a></h3><p>Strict Consistency => updates visible everywhere immediately</p><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/strict.png alt=strict.png></p><ul><li>In practice<ul><li>Even on single SMP no guarantees on order without extra locking and synchronization</li><li>in DS, latency and message reorder make this even harder</li><li>Hence almost impossible to guarantee strict consistency</li></ul></li></ul><h3 id=sequential-consistency>Sequential Consistency<a hidden class=anchor aria-hidden=true href=#sequential-consistency>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/seq.png alt=seq.png></p><p>Sequential consistency =></p><ul><li>memory updates from different processors may be arbitrarily interleaved</li><li>All processes will see the same interleaving</li><li>Operations from the same process always appearin order they were issued</li></ul><h3 id=causal-consistency>Causal Consistency<a hidden class=anchor aria-hidden=true href=#causal-consistency>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/causal.png alt=causal.png></p><ul><li>For writes not causally related, &ldquo;concurrent&rdquo; writes doesnt gurantee.</li><li>Don&rsquo;t permit arbitrary ordering from same process writer</li></ul><h3 id=weak-consistency>Weak Consistency<a hidden class=anchor aria-hidden=true href=#weak-consistency>#</a></h3><p><img loading=lazy src=https://spcdn.pages.dev/blog/os/weak.png alt=weak.png></p><ul><li>Use of synchronization<ul><li>Synchronization point => operations that are available (R,W,Sync)</li><li>all updates prior to a sync point will be visible</li><li>no guarantee what happens in between</li></ul></li></ul><p><strong>+</strong> limit data movement of coherence operations</p><p><strong>-</strong> maintain extra state for additional operations</p><ul><li>Variations:<ul><li>Single sync operation (sync)</li><li>Seperate sync per surface of state (page)</li><li>Seperate &ldquo;entry/acquire&rdquo; vs &ldquo;exit/release&rdquo; operations</li></ul></li></ul><hr></div><footer class=post-footer><ul class=post-tags><li><a href=https://samirpaulb.github.io/tags/computer-science/>computer-science</a></li><li><a href=https://samirpaulb.github.io/tags/operating-system/>Operating System</a></li></ul><nav class=paginav><a class=prev href=https://samirpaulb.github.io/posts/system-design-course/><span class=title>« Prev</span><br><span>System Design Course</span>
</a><a class=next href=https://samirpaulb.github.io/posts/pyshooter/><span class=title>Next »</span><br><span>PyShooter Python Game</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Operating System Notes For Placement on x" href="https://x.com/intent/tweet/?text=Operating%20System%20Notes%20For%20Placement&amp;url=https%3a%2f%2fsamirpaulb.github.io%2fposts%2foperating-system-notes-for-placement%2f&amp;hashtags=computer-science%2cOperatingSystem"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Operating System Notes For Placement on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsamirpaulb.github.io%2fposts%2foperating-system-notes-for-placement%2f&amp;title=Operating%20System%20Notes%20For%20Placement&amp;summary=Operating%20System%20Notes%20For%20Placement&amp;source=https%3a%2f%2fsamirpaulb.github.io%2fposts%2foperating-system-notes-for-placement%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Operating System Notes For Placement on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsamirpaulb.github.io%2fposts%2foperating-system-notes-for-placement%2f&title=Operating%20System%20Notes%20For%20Placement"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Operating System Notes For Placement on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsamirpaulb.github.io%2fposts%2foperating-system-notes-for-placement%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Operating System Notes For Placement on whatsapp" href="https://api.whatsapp.com/send?text=Operating%20System%20Notes%20For%20Placement%20-%20https%3a%2f%2fsamirpaulb.github.io%2fposts%2foperating-system-notes-for-placement%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Operating System Notes For Placement on telegram" href="https://telegram.me/share/url?text=Operating%20System%20Notes%20For%20Placement&amp;url=https%3a%2f%2fsamirpaulb.github.io%2fposts%2foperating-system-notes-for-placement%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Operating System Notes For Placement on ycombinator" href="https://news.ycombinator.com/submitlink?t=Operating%20System%20Notes%20For%20Placement&u=https%3a%2f%2fsamirpaulb.github.io%2fposts%2foperating-system-notes-for-placement%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://samirpaulb.github.io/>Samir Paul</a></span>
<span>• <a href=/sitemap.xml>Sitemap</a> • <a href=/privacy>Privacy</a> • <a href=/disclaimer>Disclaimer</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script defer loading=lazy>window.addEventListener("DOMContentLoaded",function(){for(var n=document.getElementsByTagName("a"),t=0;t<n.length;t++)n[t].hostname!==window.location.hostname&&(n[t].setAttribute("target","_blank"),n[t].setAttribute("rel","noopener"))})</script><script defer loading=lazy>if("serviceWorker"in navigator){const e=!0,t=["index","next","prev","prefetch"];function prefetchCache(){if(navigator.serviceWorker.controller){let e=document.querySelectorAll(t.map(e=>"link[rel="+e+"]").join(","));e.length>0&&Array.from(e).map(e=>{let t=e.getAttribute("href");navigator.serviceWorker.controller.postMessage({action:"cache",url:t})})}}navigator.serviceWorker.register("/sw.js",{scope:"/"}).then(()=>{console.log("Service Worker Registered")}),navigator.serviceWorker.ready.then(()=>{e&&prefetchCache()})}</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>